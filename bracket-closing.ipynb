{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understanding bracket closing in GPT-Neo\n",
    "\n",
    "The goal of this notebook is to explore the phenomenon of bracket closing in the [GPT-Neo 125M model](https://www.eleuther.ai/artifacts/gpt-neo), whereby it can correctly match open parentheses `([{<` with their corresponding closing versions `)]}>`.\n",
    "\n",
    "This is [Problem 2.13](https://www.alignmentforum.org/s/yivyHaCAmMJ3CqSyj/p/XNjRwEX9kxbpzWFWd#block71) in Neel Nanda's [200 Concrete Open Problems in Mechanistic Interpretability](https://www.alignmentforum.org/posts/LbrPTJ4fmABEdEnLf/200-concrete-open-problems-in-mechanistic-interpretability). The first goal is to figure out how the model determines whether an opening or closing bracket is more appropriate, and the second is to figure out how it knows the correct kind: `(`, `[`, `{` or `<`.\n",
    "\n",
    "I'm using the [TransformerLens library](https://github.com/neelnanda-io/TransformerLens), and a lot of this notebook is copied from Neel's [Exploratory Analysis notebook](https://neelnanda.io/exploratory-analysis-demo).\n",
    "\n",
    "This notebook lives in my [mechanistic interpretability GitHub repository](https://github.com/SamAdamDay/mechanistic-interpretability-projects), which also has some common utilities which I import below."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Config options\n",
    "\n",
    "DEVELOPMENT_MODE = False  # @param {type:\"boolean\"}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running as a Jupyter notebook - intended for development only!\n",
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_473822/787116065.py:15: DeprecationWarning: `magic(...)` is deprecated since IPython 0.13 (warning added in 8.1), use run_line_magic(magic_name, parameter_s).\n",
      "  ipython.magic(\"load_ext autoreload\")\n",
      "/tmp/ipykernel_473822/787116065.py:16: DeprecationWarning: `magic(...)` is deprecated since IPython 0.13 (warning added in 8.1), use run_line_magic(magic_name, parameter_s).\n",
      "  ipython.magic(\"autoreload 2\")\n"
     ]
    }
   ],
   "source": [
    "# Janky code to do different setup when run in a Colab notebook vs VSCode\n",
    "DEVELOPMENT_MODE = False\n",
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "    print(\"Running as a Colab notebook\")\n",
    "    %pip install https://github.com/SamAdamDay/mechanistic-interpretability-projects.git\n",
    "except:\n",
    "    IN_COLAB = False\n",
    "    print(\"Running as a Jupyter notebook - intended for development only!\")\n",
    "    from IPython import get_ipython\n",
    "\n",
    "    ipython = get_ipython()\n",
    "    # Code to automatically update the HookedTransformer code as its edited without restarting the kernel\n",
    "    ipython.magic(\"load_ext autoreload\")\n",
    "    ipython.magic(\"autoreload 2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using renderer: colab\n"
     ]
    }
   ],
   "source": [
    "# Plotly needs a different renderer for VSCode/Notebooks vs Colab argh\n",
    "import plotly.io as pio\n",
    "\n",
    "if IN_COLAB or not DEVELOPMENT_MODE:\n",
    "    pio.renderers.default = \"colab\"\n",
    "else:\n",
    "    pio.renderers.default = \"notebook_connected\"\n",
    "print(f\"Using renderer: {pio.renderers.default}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import things"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from pathlib import Path\n",
    "from typing import List, Union, Optional\n",
    "from functools import partial\n",
    "import copy\n",
    "import itertools\n",
    "import dataclasses\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import einops\n",
    "\n",
    "from fancy_einsum import einsum\n",
    "\n",
    "import tqdm.auto as tqdm\n",
    "\n",
    "import plotly.express as px\n",
    "\n",
    "from jaxtyping import Float, Int\n",
    "\n",
    "from transformers import AutoModelForCausalLM, AutoConfig, AutoTokenizer\n",
    "import datasets\n",
    "\n",
    "from IPython.display import HTML\n",
    "\n",
    "import circuitsvis as cv\n",
    "\n",
    "import transformer_lens\n",
    "import transformer_lens.utils as utils\n",
    "from transformer_lens.hook_points import (\n",
    "    HookedRootModule,\n",
    "    HookPoint,\n",
    ")  # Hooking utilities\n",
    "from transformer_lens import (\n",
    "    HookedTransformer,\n",
    "    HookedTransformerConfig,\n",
    "    FactoredMatrix,\n",
    "    ActivationCache,\n",
    ")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Turn automatic differentiation off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.grad_mode.set_grad_enabled at 0x7f1ebd784ed0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.set_grad_enabled(False)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Torch device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(tensor, renderer=None, xaxis=\"\", yaxis=\"\", **kwargs):\n",
    "    px.imshow(\n",
    "        utils.to_numpy(tensor),\n",
    "        color_continuous_midpoint=0.0,\n",
    "        color_continuous_scale=\"RdBu\",\n",
    "        labels={\"x\": xaxis, \"y\": yaxis},\n",
    "        **kwargs\n",
    "    ).show(renderer)\n",
    "\n",
    "\n",
    "def line(tensor, renderer=None, xaxis=\"\", yaxis=\"\", **kwargs):\n",
    "    px.line(utils.to_numpy(tensor), labels={\"x\": xaxis, \"y\": yaxis}, **kwargs).show(\n",
    "        renderer\n",
    "    )\n",
    "\n",
    "\n",
    "def scatter(x, y, xaxis=\"\", yaxis=\"\", caxis=\"\", renderer=None, **kwargs):\n",
    "    x = utils.to_numpy(x)\n",
    "    y = utils.to_numpy(y)\n",
    "    px.scatter(\n",
    "        y=y, x=x, labels={\"x\": xaxis, \"y\": yaxis, \"color\": caxis}, **kwargs\n",
    "    ).show(renderer)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task specification\n",
    "\n",
    "The basic task is as follows.\n",
    "\n",
    "**Task.** Given a string $s$ containing some brackets, determine: (1) if an opening or closing bracket is more appropriate and (2) which type of bracket is most appropriate.\n",
    "\n",
    "We'll be using the GPT-Neo 125M model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using pad_token, but it is not set yet.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model gpt-neo-125M into HookedTransformer\n"
     ]
    }
   ],
   "source": [
    "model = HookedTransformer.from_pretrained(\n",
    "    \"gpt-neo-125M\",\n",
    "    center_unembed=True,\n",
    "    center_writing_weights=True,\n",
    "    fold_ln=True,\n",
    "    refactor_factored_attn_matrices=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "brackets: (('(', '[', '{', '<'), (')', ']', '}', '>'))\n",
      "bracket_pairs: (('(', ')'), ('[', ']'), ('{', '}'), ('<', '>'))\n",
      "brackets_flat: ('(', '[', '{', '<', ')', ']', '}', '>')\n",
      "brackets_tokens: tensor([ 7, 58, 90, 27,  8, 60, 92, 29], device='cuda:0')\n",
      "brackets_space_tokens: tensor([ 357,  685, 1391, 1279, 1267, 2361, 1782, 1875], device='cuda:0')\n",
      "brackets_all_tokens: tensor([   7,   58,   90,   27,    8,   60,   92,   29,  357,  685, 1391, 1279,\n",
      "        1267, 2361, 1782, 1875], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "brackets = (tuple(\"([{<\"), tuple(\")]}>\"))\n",
    "bracket_pairs = tuple(zip(*brackets))\n",
    "brackets_flat = brackets[0] + brackets[1]\n",
    "\n",
    "# Get the tokens both for the brackets on their own and with a space before\n",
    "brackets_tokens = model.to_tokens(brackets_flat, prepend_bos=False).squeeze()\n",
    "brackets_space_tokens = model.to_tokens(\n",
    "    [\" \" + b for b in brackets_flat], prepend_bos=False\n",
    ").squeeze()\n",
    "brackets_all_tokens = torch.cat((brackets_tokens, brackets_space_tokens))\n",
    "\n",
    "print(\"brackets:\", brackets)\n",
    "print(\"bracket_pairs:\", bracket_pairs)\n",
    "print(\"brackets_flat:\", brackets_flat)\n",
    "print(\"brackets_tokens:\", brackets_tokens)\n",
    "print(\"brackets_space_tokens:\", brackets_space_tokens)\n",
    "print(\"brackets_all_tokens:\", brackets_all_tokens)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring model capability\n",
    "\n",
    "How good is GPT-Neo at closing brackets? In this section I explore its capabilities and try to break it. \n",
    "\n",
    "I will explore the following variations on the string $s$.\n",
    "- Whether the brackets are balanced or not.\n",
    "- The type of brackets used.\n",
    "- Whether we mix different types.\n",
    "- The complexity of the bracket structure. This can be thought of as a tree, and we can consider varying both its depth and breadth.\n",
    "- The complexity of the rest of the string.\n",
    "- Whether $s$ looks like real code. I'll look at the following ways this could fail.\n",
    "    * It's actually natural language.\n",
    "    * It's like a programming language but has syntax errors.\n",
    "    * It's valid syntax but the symbol names are gibberish/unnatural.\n",
    "    * It consists only of brackets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(exploratory_prompts): 68\n"
     ]
    }
   ],
   "source": [
    "exploratory_prompts = [\n",
    "    \"def line(tensor, renderer=None\",\n",
    "    \"def line(tensor, renderer=None)\",\n",
    "    \"exploratory_prompts = ['test'\",\n",
    "    \"exploratory_prompts = ['test']\",\n",
    "    \"exploratory_dict = {'test': 'four'\",\n",
    "    \"exploratory_dict = {'test': 'four'}\",\n",
    "    \"<template\",\n",
    "    \"<template>\",\n",
    "    \"def sieve(num, prime_list = [2, 3]\",\n",
    "    \"def sieve(num, prime_list = [2, 3])\",\n",
    "    \"exploratory_dict = {'test': [3, 5]\",\n",
    "    \"exploratory_dict = {'test': [3, 5]}\",\n",
    "    \"exploratory_dict = {'test': get_test()\",\n",
    "    \"exploratory_dict = {'test': get_test()}\",\n",
    "    \"html_to_markdown('<b>'\",\n",
    "    \"html_to_markdown('<b>')\",\n",
    "    \"<span id='name()'\",\n",
    "    \"<span id='name()'>\",\n",
    "    \"load_model(build_structure()\",\n",
    "    \"load_model(build_structure())\",\n",
    "    \"load_model(build_structure(), get_hyperparameters()\",\n",
    "    \"load_model(build_structure(), get_hyperparameters())\",\n",
    "    \"load_model(build_structure(), get_hyperparameters(), (True, False)\",\n",
    "    \"load_model(build_structure(), get_hyperparameters(), (True, False))\",\n",
    "    \"load_model(build_structure(), get_hyperparameters(True), (True, False), get_extra_config(x)\",\n",
    "    \"load_model(build_structure(), get_hyperparameters(True), (True, False), get_extra_config(x))\",\n",
    "    \"x.detach().cpu().to_numpy(\",\n",
    "    \"x.detach().cpu().to_numpy()\",\n",
    "    \"enumerate(list(zip([1,3,65], [1, 2, 3])\",\n",
    "    \"enumerate(list(zip([1,3,65], [1, 2, 3]\",\n",
    "    \"enumerate(list(zip([1,3,65], [1, 2, 3\",\n",
    "    \"enumerate(list(zip([1,3,65], [1, 2, 3]))\",\n",
    "    \"enumerate(list(zip([1,3,65], [1, 2, 3], [4, 3], [1], list(np.zeros(4))\",\n",
    "    \"enumerate(list(zip([1,3,65], [1, 2, 3], [4, 3], [1], list(np.zeros(4)))\",\n",
    "    \"zip(enumerate(list(zip([1,3,65], [1, 2, 3], [4, 3], [1], list(np.zeros(4)))), [3, 4]\",\n",
    "    \"zip(enumerate(list(zip([1,3,65], [1, 2, 3], [4, 3], [1], list(np.zeros(4)))), [3, 4])\",\n",
    "    \"zip(enumerate(list(zip([1,3,65], list(np.zeros(4)))), [3, 4], {1: 2}.items()\",\n",
    "    \"zip(enumerate(list(zip([1,3,65], list(np.zeros(4)))), [3, 4], {1: 2}.items())\",\n",
    "    \"px.imshow(to_numpy(tensor), ccm=0.0, ccs='RdBu', labels={'x':xaxis, 'y':yaxis}, **kwargs\",\n",
    "    \"px.imshow(to_numpy(tensor), ccm=0.0, ccs='RdBu', labels={'x':xaxis, 'y':yaxis}, **kwargs)\",\n",
    "    \"In the course our our analysis (which was long\",\n",
    "    \"In the course our our analysis (which was long)\",\n",
    "    \"He was eating a apple [sic\",\n",
    "    \"He was eating a apple [sic]\",\n",
    "    \"In the course our our analysis (which was long (though not too long\",\n",
    "    \"In the course our our analysis (which was long (though not too long))\",\n",
    "    \"def sieve(,num prime_list = 2[, 3]\",\n",
    "    \"def sieve(,num prime_list = 2[, 3])\",\n",
    "    \"defn line(tensor, renderer===None\",\n",
    "    \"defn line(tensor, renderer===None)\",\n",
    "    \"exploratory_dict = {'test': [3,} 5]\",\n",
    "    \"exploratory_dict = {'test': [3,} 5\",\n",
    "    \"exploratory_prompts = ['test'(]\",\n",
    "    \"exploratory_prompts = ['test'(])\",\n",
    "    \"def safasfd(oubefwef, vcewfec=afuasvfs\",\n",
    "    \"def safasfd(oubefwef, vcewfec=afuasvfs)\",\n",
    "    \"asdjhvauyrfsac = ['asdasdasd'\",\n",
    "    \"asdjhvauyrfsac = ['asdasdasd']\",\n",
    "    \"dfc = {'sdasd': 'casdasd'\",\n",
    "    \"dfc = {'sdasd': 'casdasd'}\",\n",
    "    \"<bwevzcxc\",\n",
    "    \"<bwevzcxc>\",\n",
    "    \"([]\",\n",
    "    \"([])\",\n",
    "    \"([({},[{()}])])\",\n",
    "    \"([({},[{()}])]\",\n",
    "    \"([({},[{()}])\",\n",
    "    \"([({},[{()}]\",\n",
    "]\n",
    "print(\"len(exploratory_prompts):\", len(exploratory_prompts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exp_prompt_tokens: torch.Size([68, 47])\n"
     ]
    }
   ],
   "source": [
    "# Compute the token length of each prompt, so we know where the next-token\n",
    "# prediction will be\n",
    "exp_prompt_token_lengths = []\n",
    "for prompt in exploratory_prompts:\n",
    "    prompt_tokens = model.to_tokens(prompt)\n",
    "    exp_prompt_token_lengths.append(prompt_tokens.shape[1])\n",
    "\n",
    "# Convert all the prompts to tokens, padding to make them the same length\n",
    "exp_prompt_tokens = model.to_tokens(exploratory_prompts)\n",
    "exp_prompt_tokens.to(device)\n",
    "\n",
    "print(\"exp_prompt_tokens:\", exp_prompt_tokens.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([68, 16])\n"
     ]
    }
   ],
   "source": [
    "def compute_bracket_scores(\n",
    "    prompt_tokens: Float[torch.Tensor, \"batch pos\"],\n",
    "    prompt_token_lengths: Optional[list] = None,\n",
    "):\n",
    "    \"\"\"Computes the conditional prob that the next token is each bracket\n",
    "\n",
    "    Conditioned on the next token actually being a bracket\n",
    "    \"\"\"\n",
    "\n",
    "    num_prompts = prompt_tokens.shape[0]\n",
    "\n",
    "    all_logits = model(prompt_tokens, return_type=\"logits\")  # batch pos d_vocab\n",
    "\n",
    "    d_vocab = all_logits.shape[2]\n",
    "\n",
    "    # Select the last token from each\n",
    "    if prompt_token_lengths is None:\n",
    "        logits = all_logits[:, prompt_tokens.shape[1]-1, :]  # batch d_vocab\n",
    "    else:\n",
    "        indices = torch.tensor(prompt_token_lengths).to(device) # batch\n",
    "        indices = indices.reshape((num_prompts, 1, 1)) # batch 1 1\n",
    "        indices = indices.repeat((1, 1, d_vocab)) # batch 1 d_vocab\n",
    "        logits = torch.gather(all_logits, 1, indices).squeeze()  # batch d_vocab\n",
    "\n",
    "    probs = F.softmax(logits, dim=1)  # batch d_vocab\n",
    "\n",
    "    # Compute the probability for each bracket and spaced bracket, conditioned\n",
    "    # on the fact that it is a bracket\n",
    "    cond_probs = probs[:, brackets_all_tokens]  # batch (2 n_brackets)\n",
    "    cond_probs = F.normalize(cond_probs, p=1.0, dim=1)\n",
    "\n",
    "    print(cond_probs.shape)\n",
    "\n",
    "\n",
    "compute_bracket_scores(exp_prompt_tokens, exp_prompt_token_lengths)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mech-interp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
