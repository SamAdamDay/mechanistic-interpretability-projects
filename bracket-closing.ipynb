{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understanding bracket closing in GPT-Neo\n",
    "\n",
    "The goal of this notebook is to explore the phenomenon of bracket closing in the [GPT-Neo 125M model](https://www.eleuther.ai/artifacts/gpt-neo), whereby it can correctly match open parentheses `([{<` with their corresponding closing versions `)]}>`.\n",
    "\n",
    "This is [Problem 2.13](https://www.alignmentforum.org/s/yivyHaCAmMJ3CqSyj/p/XNjRwEX9kxbpzWFWd#block71) in Neel Nanda's [200 Concrete Open Problems in Mechanistic Interpretability](https://www.alignmentforum.org/posts/LbrPTJ4fmABEdEnLf/200-concrete-open-problems-in-mechanistic-interpretability). The first goal is to figure out how the model determines whether an opening or closing bracket is more appropriate, and the second is to figure out how it knows the correct kind: `(`, `[`, `{` or `<`.\n",
    "\n",
    "I'm using the [TransformerLens library](https://github.com/neelnanda-io/TransformerLens), and a lot of this notebook is copied from Neel's [Exploratory Analysis notebook](https://neelnanda.io/exploratory-analysis-demo). See that notebook for more details explanation of the techniques used.\n",
    "\n",
    "This notebook lives in my [mechanistic interpretability GitHub repository](https://github.com/SamAdamDay/mechanistic-interpretability-projects)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running as a Jupyter notebook - intended for development only!\n",
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_23767/2956225259.py:14: DeprecationWarning: `magic(...)` is deprecated since IPython 0.13 (warning added in 8.1), use run_line_magic(magic_name, parameter_s).\n",
      "  ipython.magic(\"load_ext autoreload\")\n",
      "/tmp/ipykernel_23767/2956225259.py:15: DeprecationWarning: `magic(...)` is deprecated since IPython 0.13 (warning added in 8.1), use run_line_magic(magic_name, parameter_s).\n",
      "  ipython.magic(\"autoreload 2\")\n"
     ]
    }
   ],
   "source": [
    "# Janky code to do different setup when run in a Colab notebook vs VSCode\n",
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "    print(\"Running as a Colab notebook\")\n",
    "    %pip install https://github.com/SamAdamDay/mechanistic-interpretability-projects.git\n",
    "except:\n",
    "    IN_COLAB = False\n",
    "    print(\"Running as a Jupyter notebook - intended for development only!\")\n",
    "    from IPython import get_ipython\n",
    "\n",
    "    ipython = get_ipython()\n",
    "    # Code to automatically update the HookedTransformer code as its edited without restarting the kernel\n",
    "    ipython.magic(\"load_ext autoreload\")\n",
    "    ipython.magic(\"autoreload 2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using renderer: notebook_connected\n"
     ]
    }
   ],
   "source": [
    "# Plotly needs a different renderer for VSCode/Notebooks vs Colab argh\n",
    "import plotly.io as pio\n",
    "\n",
    "if IN_COLAB:\n",
    "    pio.renderers.default = \"colab\"\n",
    "else:\n",
    "    pio.renderers.default = \"notebook_connected\"\n",
    "print(f\"Using renderer: {pio.renderers.default}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import things"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from pathlib import Path\n",
    "from typing import List, Union, Optional\n",
    "from functools import partial\n",
    "import copy\n",
    "import itertools\n",
    "import dataclasses\n",
    "from collections import OrderedDict\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import einops\n",
    "\n",
    "from fancy_einsum import einsum\n",
    "\n",
    "import tqdm.auto as tqdm\n",
    "\n",
    "import plotly.express as px\n",
    "\n",
    "from jaxtyping import Float, Int\n",
    "\n",
    "from transformers import AutoModelForCausalLM, AutoConfig, AutoTokenizer\n",
    "import datasets\n",
    "\n",
    "from IPython.display import HTML\n",
    "\n",
    "import circuitsvis as cv\n",
    "from circuitsvis.utils.render import RenderedHTML\n",
    "\n",
    "import transformer_lens\n",
    "import transformer_lens.utils as utils\n",
    "from transformer_lens.hook_points import (\n",
    "    HookedRootModule,\n",
    "    HookPoint,\n",
    ")  # Hooking utilities\n",
    "from transformer_lens import (\n",
    "    HookedTransformer,\n",
    "    HookedTransformerConfig,\n",
    "    FactoredMatrix,\n",
    "    ActivationCache,\n",
    ")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Turn automatic differentiation off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.grad_mode.set_grad_enabled at 0x7fd99042e790>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.set_grad_enabled(False)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Torch device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sam/.virtualenvs/mech-interp/lib/python3.11/site-packages/torch/cuda/__init__.py:88: UserWarning:\n",
      "\n",
      "CUDA initialization: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:109.)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(tensor, renderer=None, **kwargs):\n",
    "    px.imshow(\n",
    "        utils.to_numpy(tensor),\n",
    "        color_continuous_midpoint=0.0,\n",
    "        color_continuous_scale=\"RdBu\",\n",
    "        **kwargs\n",
    "    ).show(renderer)\n",
    "\n",
    "\n",
    "def line(tensor, renderer=None, **kwargs):\n",
    "    px.line(y=utils.to_numpy(tensor), **kwargs).show(renderer)\n",
    "# def line(tensor, renderer=None, xaxis=\"\", yaxis=\"\", **kwargs):\n",
    "#     px.line(utils.to_numpy(tensor), labels={\"x\": xaxis, \"y\": yaxis}, **kwargs).show(\n",
    "#         renderer\n",
    "#     )\n",
    "\n",
    "\n",
    "def scatter(x, y, xaxis=\"\", yaxis=\"\", caxis=\"\", renderer=None, **kwargs):\n",
    "    x = utils.to_numpy(x)\n",
    "    y = utils.to_numpy(y)\n",
    "    px.scatter(\n",
    "        y=y, x=x, labels={\"x\": xaxis, \"y\": yaxis, \"color\": caxis}, **kwargs\n",
    "    ).show(renderer)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task specification\n",
    "\n",
    "The basic task is as follows.\n",
    "\n",
    "**Task.** Given a string $s$ containing some brackets, determine: (1) if an opening or closing bracket is more appropriate and (2) which type of bracket is most appropriate.\n",
    "\n",
    "We'll be using the GPT-Neo 125M model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using pad_token, but it is not set yet.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model gpt-neo-125M into HookedTransformer\n"
     ]
    }
   ],
   "source": [
    "model = HookedTransformer.from_pretrained(\n",
    "    \"gpt-neo-125M\",\n",
    "    center_unembed=True,\n",
    "    center_writing_weights=True,\n",
    "    fold_ln=True,\n",
    "    refactor_factored_attn_matrices=True,\n",
    ")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll look at the brackets `([{<)]}>`. We want to match all tokens which either begin with a bracket, or a space followed by the bracket. We want to match for example the token ').' for the bracket `)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "brackets: (('(', '[', '{', '<'), (')', ']', '}', '>'))\n",
      "bracket_pairs: (('(', ')'), ('[', ']'), ('{', '}'), ('<', '>'))\n",
      "brackets_flat: ('(', '[', '{', '<', ')', ']', '}', '>')\n",
      "( tokens: ['(', ' (', '()', ' (@', ' (\"', ' ($', '(\"', ' ()', '();', \"('\", ' (+', ' (%)', ' (-', ' ();', ' ((', '({', '($', ' (#', \" ('\", '((', ' (.', ' (*', '().', ' (!', '(),', ' (£', '([', ' ().', '(_', '())', ' ([', ' (),', ' (~', '(-', ' (?,', ' ())', '():', '());', ' (&', ' (−', ' (%', ' ({', '(\\\\', ' (<', ' ());', '(&', '(){', ' (_', ' (>', ' ($)', ' (=', '(*', ' (/']\n",
      "[ tokens: ['[', ' [', '[/', ' [\"', '[\"', ' [[', ' []', \"['\", '[]', ' […]', ' [];', ' [-', ' [+', ' [...]', '[_', '[[', ' [*', ' [*]', \" ['\", ' [/', ' [+]', ' [(', ' [|', ' [&']\n",
      "{ tokens: ['{', ' {', '{\"', ' {\"', ' {{', ' {}', '{{', '{\\\\', ' {\\\\', ' {:', ' {*']\n",
      "< tokens: ['<', ' <', '</', ' </', ' <<', '<<', ' <=', ' <-', ' <[', ' <@', ' <!--', ' <+', '<?']\n",
      ") tokens: [')', ').', '),', ' )', ');', '):', '))', ' );', ')(', ' ).', ' ),', ')-', ')|', ' ):', ' ))', ')]', ')\"', '));', ')\\\\', ')?', '){', ')/', ').\"', ')))', ')].', ')...', '),\"', ')*', ')—', ' ));', ')).', ')!', \")'\", '))))', ')=(', ')</', ')),', ')}', ')[', ')\",', ').[', ')--', ' )))', ')=', ')+', ' )]']\n",
      "] tokens: [']', ' ]', '].', '],', ']:', '][', '];', ']]', '])', '](', ' ],', '],\"', ' ].', ']=', ' ];', '].\"', ']\"', ' ])', ']).', ']);', '],[', ' ][', '][/', ']-', ']),', ']+', ']}', \"]'\"]\n",
      "} tokens: ['}', ' }', '},', '},{\"', ' },', '},\"', '}}', ' });', ' };', '}{', '};', '});', '}.', '})', ' })', '}\\\\', ' }}', '}\"', '}:', '}}}']\n",
      "> tokens: ['>', ' >', '>>', '><', ' >>', '></', ' >>>', '>>>>', ' >=', '>,', '>\"', '>.', ' ><', '>:', '>>>', '>>>>>>>>', '>(', '>>\\\\', '>[', '>]', '>)']\n",
      "bracket_tokens_flat: torch.Size([216])\n",
      "open_bracket_tokens: torch.Size([101])\n",
      "closed_bracket_tokens: torch.Size([115])\n",
      "bracket_tokens_sizes: [53, 24, 11, 13, 46, 28, 20, 21]\n"
     ]
    }
   ],
   "source": [
    "brackets = (tuple(\"([{<\"), tuple(\")]}>\"))\n",
    "bracket_pairs = tuple(zip(*brackets))\n",
    "brackets_flat = brackets[0] + brackets[1]\n",
    "num_brackets = len(brackets_flat)\n",
    "\n",
    "# Get all (non-endoftext tokens) tokens which either start with a bracket or a\n",
    "# space followed by a bracket\n",
    "bracket_tokens = OrderedDict([(bracket, []) for bracket in brackets_flat])\n",
    "bracket_token_strs = OrderedDict([(bracket, []) for bracket in brackets_flat])\n",
    "all_tokens = model.to_str_tokens(np.arange(model.cfg.d_vocab - 1), prepend_bos=False)\n",
    "for i, token_str in enumerate(all_tokens):\n",
    "    for bracket in brackets_flat:\n",
    "        if token_str.startswith(bracket) or token_str.startswith(\" \" + bracket):\n",
    "            bracket_tokens[bracket].append(i)\n",
    "            bracket_token_strs[bracket].append(token_str)\n",
    "for bracket, tokens in bracket_tokens.items():\n",
    "    bracket_tokens[bracket] = torch.tensor(tokens)\n",
    "\n",
    "# Flatten the dict of tokens, and record the sizes of each list\n",
    "bracket_tokens_flat = torch.cat(list(bracket_tokens.values()))\n",
    "bracket_tokens_sizes = [tokens.shape[0] for tokens in bracket_tokens.values()]\n",
    "\n",
    "# Select the open and closed bracket tokens\n",
    "num_open_bracket_tokens = sum(bracket_tokens_sizes[:num_brackets // 2])\n",
    "open_bracket_tokens = bracket_tokens_flat[:num_open_bracket_tokens]\n",
    "closed_bracket_tokens = bracket_tokens_flat[num_open_bracket_tokens:]\n",
    "\n",
    "print(\"brackets:\", brackets)\n",
    "print(\"bracket_pairs:\", bracket_pairs)\n",
    "print(\"brackets_flat:\", brackets_flat)\n",
    "for bracket, token_strs in bracket_token_strs.items():\n",
    "    print(f\"{bracket} tokens:\", token_strs)\n",
    "print(\"bracket_tokens_flat:\", bracket_tokens_flat.shape)\n",
    "print(\"open_bracket_tokens:\", open_bracket_tokens.shape)\n",
    "print(\"closed_bracket_tokens:\", closed_bracket_tokens.shape)\n",
    "print(\"bracket_tokens_sizes:\", bracket_tokens_sizes)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring model capability\n",
    "\n",
    "How good is GPT-Neo at closing brackets? In this section I explore its capabilities and try to break it. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will explore the following variations on the string $s$.\n",
    "- Whether the brackets are balanced or not.\n",
    "- The type of brackets used.\n",
    "- Whether we mix different types.\n",
    "- The complexity of the bracket structure. This can be thought of as a tree, and we can consider varying both its depth and breadth.\n",
    "- The complexity of the rest of the string.\n",
    "- Whether $s$ looks like real code. I'll look at the following ways this could fail.\n",
    "    * It's actually natural language.\n",
    "    * It's like a programming language but has syntax errors.\n",
    "    * It's valid syntax but the symbol names are gibberish/unnatural.\n",
    "    * It consists only of brackets."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory prompts\n",
    "\n",
    "I will test the following prompts, to see what the model does."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_exploratory_prompts: 72\n"
     ]
    }
   ],
   "source": [
    "exploratory_prompts = [\n",
    "    \"def line(tensor, renderer=None\",\n",
    "    \"def line(tensor, renderer=None)\",\n",
    "    \"exploratory_prompts = ['test'\",\n",
    "    \"exploratory_prompts = ['test']\",\n",
    "    \"array[0\",\n",
    "    \"array[0]\",\n",
    "    \"exploratory_dict = {'test': 'four'\",\n",
    "    \"exploratory_dict = {'test': 'four'}\",\n",
    "    \"<template\",\n",
    "    \"<template>\",\n",
    "    \"def sieve(num, prime_list = [2, 3]\",\n",
    "    \"def sieve(num, prime_list = [2, 3])\",\n",
    "    \"exploratory_dict = {'test': [3, 5]\",\n",
    "    \"exploratory_dict = {'test': [3, 5]}\",\n",
    "    \"exploratory_dict = {'test': get_test()\",\n",
    "    \"exploratory_dict = {'test': get_test()}\",\n",
    "    \"html_to_markdown('<s>'\",\n",
    "    \"html_to_markdown('<s>')\",\n",
    "    \"<table id='name()'\",\n",
    "    \"<table id='name()'>\",\n",
    "    \"load_model(build_structure()\",\n",
    "    \"load_model(build_structure())\",\n",
    "    \"load_model(build_structure(), get_hyperparameters()\",\n",
    "    \"load_model(build_structure(), get_hyperparameters())\",\n",
    "    \"load_model(build_structure(), get_hyperparameters(), (True, False)\",\n",
    "    \"load_model(build_structure(), get_hyperparameters(), (True, False))\",\n",
    "    \"load_model(build_structure(), get_hyperparameters(True), (True, False), get_extra_config(x)\",\n",
    "    \"load_model(build_structure(), get_hyperparameters(True), (True, False), get_extra_config(x))\",\n",
    "    \"x.detach().cpu().to_numpy(\",\n",
    "    \"x.detach().cpu().to_numpy()\",\n",
    "    \"enumerate(list(zip([1,3,65], [1, 2, 3])\",\n",
    "    \"enumerate(list(zip([1,3,65], [1, 2, 3]\",\n",
    "    \"enumerate(list(zip([1,3,65], [1, 2, 3\",\n",
    "    \"enumerate(list(zip([1,3,65], [1, 2, 3]))\",\n",
    "    \"enumerate(list(zip([1,3,65], [1, 2, 3], [4, 3], [1], list(np.zeros(4))\",\n",
    "    \"enumerate(list(zip([1,3,65], [1, 2, 3], [4, 3], [1], list(np.zeros(4)))\",\n",
    "    \"zip(enumerate(list(zip([1,3,65], [1, 2, 3], [4, 3], [1], list(np.zeros(4)))), [3, 4]\",\n",
    "    \"zip(enumerate(list(zip([1,3,65], [1, 2, 3], [4, 3], [1], list(np.zeros(4)))), [3, 4])\",\n",
    "    \"zip(enumerate(list(zip([1,3,65], list(np.zeros(4)))), [3, 4], {1: 2}.items()\",\n",
    "    \"zip(enumerate(list(zip([1,3,65], list(np.zeros(4)))), [3, 4], {1: 2}.items())\",\n",
    "    \"list())))).append(x\",\n",
    "    \"list())))).append(x)\",\n",
    "    \"px.imshow(to_numpy(tensor), ccm=0.0, ccs='RdBu', labels={'x':xaxis, 'y':yaxis}, **kwargs\",\n",
    "    \"px.imshow(to_numpy(tensor), ccm=0.0, ccs='RdBu', labels={'x':xaxis, 'y':yaxis}, **kwargs)\",\n",
    "    \"In the course our our analysis (which was long\",\n",
    "    \"In the course our our analysis (which was long)\",\n",
    "    \"He was eating a apple [sic\",\n",
    "    \"He was eating a apple [sic]\",\n",
    "    \"In the course our our analysis (which was long (though not too long\",\n",
    "    \"In the course our our analysis (which was long (though not too long))\",\n",
    "    \"def sieve(,num prime_list = 2[, 3]\",\n",
    "    \"def sieve(,num prime_list = 2[, 3])\",\n",
    "    \"defn line(tensor, renderer===None\",\n",
    "    \"defn line(tensor, renderer===None)\",\n",
    "    \"exploratory_dict = {'test': [3,} 5]\",\n",
    "    \"exploratory_dict = {'test': [3,} 5\",\n",
    "    \"exploratory_prompts = ['test'(]\",\n",
    "    \"exploratory_prompts = ['test'(])\",\n",
    "    \"def safasfd(oubefwef, vcewfec=afuasvfs\",\n",
    "    \"def safasfd(oubefwef, vcewfec=afuasvfs)\",\n",
    "    \"asdjhvauyrfsac = ['asdasdasd'\",\n",
    "    \"asdjhvauyrfsac = ['asdasdasd']\",\n",
    "    \"dfc = {'sdasd': 'casdasd'\",\n",
    "    \"dfc = {'sdasd': 'casdasd'}\",\n",
    "    \"<bwevzcxc\",\n",
    "    \"<bwevzcxc>\",\n",
    "    \"([]\",\n",
    "    \"([])\",\n",
    "    \"([({},[{()}])])\",\n",
    "    \"([({},[{()}])]\",\n",
    "    \"([({},[{()}])\",\n",
    "    \"([({},[{()}]\",\n",
    "]\n",
    "num_exploratory_prompts = len(exploratory_prompts)\n",
    "print(\"num_exploratory_prompts:\", num_exploratory_prompts)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's convert the prompts to padded tokens, keeping track of each unpadded length, so we can find the next predicted token for each one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exp_prompt_tokens: torch.Size([72, 47])\n"
     ]
    }
   ],
   "source": [
    "# Compute the token length of each prompt, so we know where the next-token\n",
    "# prediction will be\n",
    "exp_prompt_token_lengths = []\n",
    "for prompt in exploratory_prompts:\n",
    "    prompt_tokens = model.to_tokens(prompt)\n",
    "    exp_prompt_token_lengths.append(prompt_tokens.shape[1])\n",
    "\n",
    "# Convert all the prompts to tokens, padding to make them the same length\n",
    "exp_prompt_tokens = model.to_tokens(exploratory_prompts)\n",
    "exp_prompt_tokens.to(device)\n",
    "\n",
    "print(\"exp_prompt_tokens:\", exp_prompt_tokens.shape)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Investigating performance\n",
    "\n",
    "The following function computes runs the model, looks at the predictions for the next tokens for each prompt, and computes the probability that it each possible bracket (including spaces), conditioned on that it actually is a bracket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_bracket_scores(\n",
    "    prompt_tokens: Float[torch.Tensor, \"batch pos\"],\n",
    "    prompt_token_lengths: Optional[list[int]] = None,\n",
    ") -> Float[torch.Tensor, \"batch n_brackets\"]:\n",
    "    \"\"\"Computes the conditional prob that the next token is each bracket\n",
    "\n",
    "    Conditioned on the next token actually being a bracket\n",
    "    \"\"\"\n",
    "\n",
    "    num_prompts = prompt_tokens.shape[0]\n",
    "\n",
    "    all_logits = model(prompt_tokens, return_type=\"logits\")  # batch pos d_vocab\n",
    "\n",
    "    d_vocab = all_logits.shape[2]\n",
    "\n",
    "    # Select the last token from each\n",
    "    if prompt_token_lengths is None:\n",
    "        logits = all_logits[:, prompt_tokens.shape[1] - 1, :]  # batch d_vocab\n",
    "    else:\n",
    "        indices = torch.tensor(prompt_token_lengths, device=device) - 1  # batch\n",
    "        indices = indices.reshape((num_prompts, 1, 1))  # batch 1 1\n",
    "        indices = indices.repeat((1, 1, d_vocab))  # batch 1 d_vocab\n",
    "        logits = torch.gather(all_logits, 1, indices).squeeze()  # batch d_vocab\n",
    "\n",
    "    probs = F.softmax(logits, dim=1)  # batch d_vocab\n",
    "\n",
    "    # Compute the probability for each bracket and spaced bracket, conditioned\n",
    "    # on the fact that it is a bracket\n",
    "    cond_probs = probs[:, bracket_tokens_flat]  # batch (2 n_bracket_tokens)\n",
    "    cond_probs = F.normalize(cond_probs, p=1.0, dim=1)\n",
    "\n",
    "    # Combine the conditional probabilities for each bracket\n",
    "    cond_probs_combined = torch.zeros((num_prompts, num_brackets))\n",
    "    index = 0\n",
    "    for i, size in enumerate(bracket_tokens_sizes):\n",
    "        cond_probs_combined[:, i] = cond_probs[:, index : index + size].sum(dim=1)\n",
    "        index += size\n",
    "\n",
    "    return cond_probs_combined\n",
    "\n",
    "\n",
    "bracket_scores = compute_bracket_scores(exp_prompt_tokens, exp_prompt_token_lengths)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's display these in a nice chart. I break it up into two since there are a lot of prompts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_bracket_scores(\n",
    "    prompts: list[str],\n",
    "    bracket_scores: Float[torch.Tensor, \"batch n_brackets\"],\n",
    "    height_scale: int = 30,\n",
    "):\n",
    "    \"\"\"Display the bracket scores nicely\"\"\"\n",
    "    num_prompts = len(prompts)\n",
    "    fig = px.imshow(\n",
    "        utils.to_numpy(bracket_scores),\n",
    "        color_continuous_scale=\"blues\",\n",
    "        labels=dict(x=\"Bracket\", color=\"Conditional Probability\"),\n",
    "        x=brackets_flat,\n",
    "        y=prompts,\n",
    "        height=height_scale * num_prompts,\n",
    "    )\n",
    "    for ix, bracket in enumerate(brackets_flat):\n",
    "        for iy in range(num_prompts):\n",
    "            fig.add_annotation(\n",
    "                x=ix,\n",
    "                y=iy,\n",
    "                text=bracket,\n",
    "                showarrow=False,\n",
    "                font_color=\"orange\",\n",
    "            )\n",
    "    fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-2.20.0.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>                            <div id=\"d083d851-ab26-4c19-97b1-011946a21603\" class=\"plotly-graph-div\" style=\"height:1080px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"d083d851-ab26-4c19-97b1-011946a21603\")) {                    Plotly.newPlot(                        \"d083d851-ab26-4c19-97b1-011946a21603\",                        [{\"coloraxis\":\"coloraxis\",\"name\":\"0\",\"x\":[\"(\",\"[\",\"{\",\"<\",\")\",\"]\",\"}\",\">\"],\"y\":[\"def line(tensor, renderer=None\",\"def line(tensor, renderer=None)\",\"exploratory_prompts = ['test'\",\"exploratory_prompts = ['test']\",\"array[0\",\"array[0]\",\"exploratory_dict = {'test': 'four'\",\"exploratory_dict = {'test': 'four'}\",\"<template\",\"<template>\",\"def sieve(num, prime_list = [2, 3]\",\"def sieve(num, prime_list = [2, 3])\",\"exploratory_dict = {'test': [3, 5]\",\"exploratory_dict = {'test': [3, 5]}\",\"exploratory_dict = {'test': get_test()\",\"exploratory_dict = {'test': get_test()}\",\"html_to_markdown('<s>'\",\"html_to_markdown('<s>')\",\"<table id='name()'\",\"<table id='name()'>\",\"load_model(build_structure()\",\"load_model(build_structure())\",\"load_model(build_structure(), get_hyperparameters()\",\"load_model(build_structure(), get_hyperparameters())\",\"load_model(build_structure(), get_hyperparameters(), (True, False)\",\"load_model(build_structure(), get_hyperparameters(), (True, False))\",\"load_model(build_structure(), get_hyperparameters(True), (True, False), get_extra_config(x)\",\"load_model(build_structure(), get_hyperparameters(True), (True, False), get_extra_config(x))\",\"x.detach().cpu().to_numpy(\",\"x.detach().cpu().to_numpy()\",\"enumerate(list(zip([1,3,65], [1, 2, 3])\",\"enumerate(list(zip([1,3,65], [1, 2, 3]\",\"enumerate(list(zip([1,3,65], [1, 2, 3\",\"enumerate(list(zip([1,3,65], [1, 2, 3]))\",\"enumerate(list(zip([1,3,65], [1, 2, 3], [4, 3], [1], list(np.zeros(4))\",\"enumerate(list(zip([1,3,65], [1, 2, 3], [4, 3], [1], list(np.zeros(4)))\"],\"z\":[[1.609617356734816e-05,3.3054224331863225e-05,1.992840594766676e-07,2.785497201784892e-07,0.9999461770057678,1.3260228115541395e-06,2.568428271843004e-06,7.152826242418087e-07],[0.3173849582672119,0.34839096665382385,0.22829656302928925,0.008658126927912235,0.08334029465913773,0.0021563128102570772,5.715771476388909e-05,0.01171552762389183],[5.701024201698601e-05,8.528495527571067e-05,1.4170408348945784e-06,0.00010017160093411803,3.256875788792968e-05,0.9981484413146973,0.0013124402612447739,0.00026260322192683816],[0.06506045162677765,0.06276267766952515,0.0041067167185246944,0.01613546721637249,0.47414323687553406,0.25735458731651306,0.10328751057386398,0.01714983582496643],[7.933303277241066e-05,0.00012013951345579699,1.8481894585420378e-05,0.00019387408974580467,0.00020359770860522985,0.9987819790840149,0.0004479825438465923,0.0001547060237498954],[0.04054002836346626,0.0996202751994133,0.09309915453195572,0.1915598064661026,0.229003444314003,0.2099682241678238,0.032061509788036346,0.10414756834506989],[7.024689693935215e-05,9.727911674417555e-05,9.942711585608777e-06,4.211832128930837e-05,4.4795464759772585e-07,7.518713391618803e-05,0.9996981620788574,6.701509391859872e-06],[0.03930394724011421,0.5143156051635742,0.026576373726129532,0.010578923858702183,0.21011267602443695,0.1617252230644226,0.031852636486291885,0.005534815602004528],[6.201586074894294e-05,3.1350384233519435e-05,4.58669592262595e-06,3.2986961741698906e-05,1.0613031236061943e-06,2.1040624176293932e-07,2.2042199177008115e-08,0.999867856502533],[0.003987165633589029,0.0003280879172962159,0.32636889815330505,0.663361132144928,0.0021191260311752558,0.00011482479749247432,0.0021040833089500666,0.0016169665614143014],[0.0003370226768311113,0.00044635715312324464,5.43029818800278e-05,1.3440484281090903e-06,0.9991406798362732,9.687974852568004e-06,9.131572937803867e-07,9.590323315933347e-06],[0.03845832869410515,0.2305075079202652,0.6141166687011719,0.0030709197744727135,0.10273788869380951,0.004210366867482662,0.00012686557602137327,0.006771921180188656],[0.00017551102791912854,0.000326345965731889,0.00013521083747036755,7.793560507707298e-05,4.511602583079366e-06,0.00018504710169509053,0.9990638494491577,3.189227936672978e-05],[0.022005023434758186,0.09190785884857178,0.005961531773209572,0.02382291853427887,0.20523318648338318,0.35139229893684387,0.29584819078445435,0.0038288270588964224],[0.0006291572353802621,0.007054484449326992,5.253767085378058e-05,0.0001529658038634807,6.04801016379497e-06,8.591034566052258e-05,0.9920012354850769,1.763384534569923e-05],[0.046468764543533325,0.386040061712265,0.018732581287622452,0.006070784758776426,0.3840903043746948,0.1094626635313034,0.04558943212032318,0.003545647719874978],[0.00863292533904314,0.026185426861047745,0.05960044637322426,0.02563023567199707,0.8597300052642822,0.009833105839788914,0.0050544473342597485,0.005333516281098127],[0.00745142949745059,0.22554203867912292,0.4050668478012085,0.07125060260295868,0.23563911020755768,0.02786274626851082,0.0151916379109025,0.011995525099337101],[0.0003436957485973835,0.0017240454908460379,0.0004237227258272469,0.004584697540849447,0.00022299525153357536,0.000546713883522898,0.00011198189167771488,0.9920421838760376],[0.0020694041159003973,0.004159319680184126,0.05741678550839424,0.9188671112060547,0.005957946181297302,0.0008211928652599454,0.010118766687810421,0.0005898329545743763],[0.011611465364694595,0.04259537160396576,0.0920693427324295,0.08050640672445297,0.7701142430305481,2.899942046497017e-05,3.718504012795165e-05,0.003037415212020278],[0.0008271806873381138,0.010552724823355675,0.9398097991943359,0.023127006366848946,0.012579532340168953,0.002497964771464467,0.0032037030905485153,0.007402563001960516],[0.00959315150976181,0.20443037152290344,0.007975746877491474,0.007019079755991697,0.7678603529930115,2.105999374180101e-05,9.49143577599898e-05,0.0030053460504859686],[0.002306845737621188,0.0952053964138031,0.6377246975898743,0.035850707441568375,0.12021268159151077,0.03836676850914955,0.04752829298377037,0.02280428633093834],[0.1416509598493576,0.08432875573635101,0.2721467614173889,0.023991448804736137,0.4356921315193176,0.0022873838897794485,0.0022391004022210836,0.03766360878944397],[0.06479150801897049,0.04926690831780434,0.16305406391620636,0.026185180991888046,0.6122965812683105,0.027922168374061584,0.012721704319119453,0.04376155510544777],[0.02259320765733719,0.06590501219034195,0.07726345211267471,0.014713450334966183,0.7394962310791016,0.010649065487086773,0.024793215095996857,0.044586002826690674],[0.01581173576414585,0.06648525595664978,0.19624970853328705,0.03211677446961403,0.5858823657035828,0.052803441882133484,0.00741581991314888,0.04323483631014824],[0.06164143979549408,0.7988715171813965,0.05018547177314758,0.014927104115486145,0.0549805574119091,0.0037797843106091022,0.00688927061855793,0.008724731393158436],[0.04242953658103943,0.22278039157390594,0.0026780515909194946,0.02065380848944187,0.6336902976036072,0.025079194456338882,0.0239628404378891,0.028725886717438698],[0.00025303184520453215,0.013660309836268425,0.0006482136668637395,0.0002263985079480335,0.9685782194137573,0.016530495136976242,2.914366814366076e-05,7.431350968545303e-05],[6.615332677029073e-05,6.781219417462125e-05,1.5903136954875663e-05,1.122779940487817e-05,0.9994860291481018,0.00034838810097426176,1.1610555930019473e-06,3.5140078580297995e-06],[2.929209040303249e-05,0.0001359581801807508,2.0037684862472815e-06,3.505746917653596e-06,0.00029827607795596123,0.9992111325263977,9.633033187128603e-05,0.00022338244889397174],[0.0015211787540465593,0.031201614066958427,0.0010750481160357594,0.0004477985785342753,0.9641165733337402,0.0011762977810576558,8.912254270398989e-05,0.0003722446854226291],[0.00027245012461207807,0.022021664306521416,2.7592808692133985e-05,0.00024337841023225337,0.965874433517456,0.011371328495442867,4.840717156184837e-05,0.00014080012624617666],[0.00019971512665506452,0.015324669890105724,1.8489130525267683e-05,0.00027502820012159646,0.9801182746887207,0.0035331544931977987,0.0002563177840784192,0.00027446672902442515]],\"type\":\"heatmap\",\"xaxis\":\"x\",\"yaxis\":\"y\",\"hovertemplate\":\"Bracket: %{x}<br>y: %{y}<br>Conditional Probability: %{z}<extra></extra>\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"scaleanchor\":\"y\",\"constrain\":\"domain\",\"title\":{\"text\":\"Bracket\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"autorange\":\"reversed\",\"constrain\":\"domain\"},\"coloraxis\":{\"colorbar\":{\"title\":{\"text\":\"Conditional Probability\"}},\"colorscale\":[[0.0,\"rgb(247,251,255)\"],[0.125,\"rgb(222,235,247)\"],[0.25,\"rgb(198,219,239)\"],[0.375,\"rgb(158,202,225)\"],[0.5,\"rgb(107,174,214)\"],[0.625,\"rgb(66,146,198)\"],[0.75,\"rgb(33,113,181)\"],[0.875,\"rgb(8,81,156)\"],[1.0,\"rgb(8,48,107)\"]]},\"margin\":{\"t\":60},\"height\":1080,\"annotations\":[{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"(\",\"x\":0,\"y\":0},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"(\",\"x\":0,\"y\":1},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"(\",\"x\":0,\"y\":2},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"(\",\"x\":0,\"y\":3},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"(\",\"x\":0,\"y\":4},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"(\",\"x\":0,\"y\":5},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"(\",\"x\":0,\"y\":6},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"(\",\"x\":0,\"y\":7},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"(\",\"x\":0,\"y\":8},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"(\",\"x\":0,\"y\":9},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"(\",\"x\":0,\"y\":10},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"(\",\"x\":0,\"y\":11},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"(\",\"x\":0,\"y\":12},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"(\",\"x\":0,\"y\":13},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"(\",\"x\":0,\"y\":14},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"(\",\"x\":0,\"y\":15},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"(\",\"x\":0,\"y\":16},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"(\",\"x\":0,\"y\":17},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"(\",\"x\":0,\"y\":18},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"(\",\"x\":0,\"y\":19},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"(\",\"x\":0,\"y\":20},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"(\",\"x\":0,\"y\":21},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"(\",\"x\":0,\"y\":22},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"(\",\"x\":0,\"y\":23},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"(\",\"x\":0,\"y\":24},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"(\",\"x\":0,\"y\":25},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"(\",\"x\":0,\"y\":26},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"(\",\"x\":0,\"y\":27},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"(\",\"x\":0,\"y\":28},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"(\",\"x\":0,\"y\":29},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"(\",\"x\":0,\"y\":30},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"(\",\"x\":0,\"y\":31},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"(\",\"x\":0,\"y\":32},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"(\",\"x\":0,\"y\":33},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"(\",\"x\":0,\"y\":34},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"(\",\"x\":0,\"y\":35},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"[\",\"x\":1,\"y\":0},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"[\",\"x\":1,\"y\":1},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"[\",\"x\":1,\"y\":2},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"[\",\"x\":1,\"y\":3},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"[\",\"x\":1,\"y\":4},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"[\",\"x\":1,\"y\":5},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"[\",\"x\":1,\"y\":6},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"[\",\"x\":1,\"y\":7},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"[\",\"x\":1,\"y\":8},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"[\",\"x\":1,\"y\":9},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"[\",\"x\":1,\"y\":10},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"[\",\"x\":1,\"y\":11},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"[\",\"x\":1,\"y\":12},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"[\",\"x\":1,\"y\":13},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"[\",\"x\":1,\"y\":14},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"[\",\"x\":1,\"y\":15},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"[\",\"x\":1,\"y\":16},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"[\",\"x\":1,\"y\":17},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"[\",\"x\":1,\"y\":18},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"[\",\"x\":1,\"y\":19},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"[\",\"x\":1,\"y\":20},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"[\",\"x\":1,\"y\":21},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"[\",\"x\":1,\"y\":22},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"[\",\"x\":1,\"y\":23},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"[\",\"x\":1,\"y\":24},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"[\",\"x\":1,\"y\":25},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"[\",\"x\":1,\"y\":26},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"[\",\"x\":1,\"y\":27},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"[\",\"x\":1,\"y\":28},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"[\",\"x\":1,\"y\":29},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"[\",\"x\":1,\"y\":30},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"[\",\"x\":1,\"y\":31},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"[\",\"x\":1,\"y\":32},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"[\",\"x\":1,\"y\":33},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"[\",\"x\":1,\"y\":34},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"[\",\"x\":1,\"y\":35},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"{\",\"x\":2,\"y\":0},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"{\",\"x\":2,\"y\":1},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"{\",\"x\":2,\"y\":2},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"{\",\"x\":2,\"y\":3},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"{\",\"x\":2,\"y\":4},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"{\",\"x\":2,\"y\":5},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"{\",\"x\":2,\"y\":6},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"{\",\"x\":2,\"y\":7},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"{\",\"x\":2,\"y\":8},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"{\",\"x\":2,\"y\":9},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"{\",\"x\":2,\"y\":10},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"{\",\"x\":2,\"y\":11},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"{\",\"x\":2,\"y\":12},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"{\",\"x\":2,\"y\":13},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"{\",\"x\":2,\"y\":14},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"{\",\"x\":2,\"y\":15},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"{\",\"x\":2,\"y\":16},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"{\",\"x\":2,\"y\":17},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"{\",\"x\":2,\"y\":18},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"{\",\"x\":2,\"y\":19},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"{\",\"x\":2,\"y\":20},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"{\",\"x\":2,\"y\":21},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"{\",\"x\":2,\"y\":22},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"{\",\"x\":2,\"y\":23},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"{\",\"x\":2,\"y\":24},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"{\",\"x\":2,\"y\":25},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"{\",\"x\":2,\"y\":26},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"{\",\"x\":2,\"y\":27},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"{\",\"x\":2,\"y\":28},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"{\",\"x\":2,\"y\":29},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"{\",\"x\":2,\"y\":30},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"{\",\"x\":2,\"y\":31},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"{\",\"x\":2,\"y\":32},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"{\",\"x\":2,\"y\":33},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"{\",\"x\":2,\"y\":34},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"{\",\"x\":2,\"y\":35},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"<\",\"x\":3,\"y\":0},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"<\",\"x\":3,\"y\":1},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"<\",\"x\":3,\"y\":2},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"<\",\"x\":3,\"y\":3},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"<\",\"x\":3,\"y\":4},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"<\",\"x\":3,\"y\":5},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"<\",\"x\":3,\"y\":6},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"<\",\"x\":3,\"y\":7},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"<\",\"x\":3,\"y\":8},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"<\",\"x\":3,\"y\":9},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"<\",\"x\":3,\"y\":10},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"<\",\"x\":3,\"y\":11},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"<\",\"x\":3,\"y\":12},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"<\",\"x\":3,\"y\":13},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"<\",\"x\":3,\"y\":14},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"<\",\"x\":3,\"y\":15},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"<\",\"x\":3,\"y\":16},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"<\",\"x\":3,\"y\":17},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"<\",\"x\":3,\"y\":18},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"<\",\"x\":3,\"y\":19},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"<\",\"x\":3,\"y\":20},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"<\",\"x\":3,\"y\":21},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"<\",\"x\":3,\"y\":22},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"<\",\"x\":3,\"y\":23},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"<\",\"x\":3,\"y\":24},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"<\",\"x\":3,\"y\":25},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"<\",\"x\":3,\"y\":26},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"<\",\"x\":3,\"y\":27},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"<\",\"x\":3,\"y\":28},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"<\",\"x\":3,\"y\":29},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"<\",\"x\":3,\"y\":30},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"<\",\"x\":3,\"y\":31},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"<\",\"x\":3,\"y\":32},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"<\",\"x\":3,\"y\":33},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"<\",\"x\":3,\"y\":34},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"<\",\"x\":3,\"y\":35},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\")\",\"x\":4,\"y\":0},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\")\",\"x\":4,\"y\":1},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\")\",\"x\":4,\"y\":2},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\")\",\"x\":4,\"y\":3},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\")\",\"x\":4,\"y\":4},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\")\",\"x\":4,\"y\":5},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\")\",\"x\":4,\"y\":6},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\")\",\"x\":4,\"y\":7},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\")\",\"x\":4,\"y\":8},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\")\",\"x\":4,\"y\":9},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\")\",\"x\":4,\"y\":10},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\")\",\"x\":4,\"y\":11},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\")\",\"x\":4,\"y\":12},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\")\",\"x\":4,\"y\":13},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\")\",\"x\":4,\"y\":14},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\")\",\"x\":4,\"y\":15},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\")\",\"x\":4,\"y\":16},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\")\",\"x\":4,\"y\":17},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\")\",\"x\":4,\"y\":18},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\")\",\"x\":4,\"y\":19},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\")\",\"x\":4,\"y\":20},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\")\",\"x\":4,\"y\":21},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\")\",\"x\":4,\"y\":22},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\")\",\"x\":4,\"y\":23},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\")\",\"x\":4,\"y\":24},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\")\",\"x\":4,\"y\":25},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\")\",\"x\":4,\"y\":26},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\")\",\"x\":4,\"y\":27},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\")\",\"x\":4,\"y\":28},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\")\",\"x\":4,\"y\":29},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\")\",\"x\":4,\"y\":30},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\")\",\"x\":4,\"y\":31},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\")\",\"x\":4,\"y\":32},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\")\",\"x\":4,\"y\":33},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\")\",\"x\":4,\"y\":34},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\")\",\"x\":4,\"y\":35},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"]\",\"x\":5,\"y\":0},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"]\",\"x\":5,\"y\":1},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"]\",\"x\":5,\"y\":2},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"]\",\"x\":5,\"y\":3},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"]\",\"x\":5,\"y\":4},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"]\",\"x\":5,\"y\":5},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"]\",\"x\":5,\"y\":6},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"]\",\"x\":5,\"y\":7},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"]\",\"x\":5,\"y\":8},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"]\",\"x\":5,\"y\":9},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"]\",\"x\":5,\"y\":10},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"]\",\"x\":5,\"y\":11},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"]\",\"x\":5,\"y\":12},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"]\",\"x\":5,\"y\":13},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"]\",\"x\":5,\"y\":14},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"]\",\"x\":5,\"y\":15},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"]\",\"x\":5,\"y\":16},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"]\",\"x\":5,\"y\":17},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"]\",\"x\":5,\"y\":18},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"]\",\"x\":5,\"y\":19},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"]\",\"x\":5,\"y\":20},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"]\",\"x\":5,\"y\":21},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"]\",\"x\":5,\"y\":22},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"]\",\"x\":5,\"y\":23},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"]\",\"x\":5,\"y\":24},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"]\",\"x\":5,\"y\":25},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"]\",\"x\":5,\"y\":26},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"]\",\"x\":5,\"y\":27},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"]\",\"x\":5,\"y\":28},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"]\",\"x\":5,\"y\":29},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"]\",\"x\":5,\"y\":30},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"]\",\"x\":5,\"y\":31},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"]\",\"x\":5,\"y\":32},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"]\",\"x\":5,\"y\":33},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"]\",\"x\":5,\"y\":34},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"]\",\"x\":5,\"y\":35},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"}\",\"x\":6,\"y\":0},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"}\",\"x\":6,\"y\":1},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"}\",\"x\":6,\"y\":2},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"}\",\"x\":6,\"y\":3},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"}\",\"x\":6,\"y\":4},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"}\",\"x\":6,\"y\":5},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"}\",\"x\":6,\"y\":6},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"}\",\"x\":6,\"y\":7},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"}\",\"x\":6,\"y\":8},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"}\",\"x\":6,\"y\":9},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"}\",\"x\":6,\"y\":10},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"}\",\"x\":6,\"y\":11},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"}\",\"x\":6,\"y\":12},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"}\",\"x\":6,\"y\":13},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"}\",\"x\":6,\"y\":14},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"}\",\"x\":6,\"y\":15},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"}\",\"x\":6,\"y\":16},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"}\",\"x\":6,\"y\":17},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"}\",\"x\":6,\"y\":18},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"}\",\"x\":6,\"y\":19},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"}\",\"x\":6,\"y\":20},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"}\",\"x\":6,\"y\":21},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"}\",\"x\":6,\"y\":22},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"}\",\"x\":6,\"y\":23},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"}\",\"x\":6,\"y\":24},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"}\",\"x\":6,\"y\":25},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"}\",\"x\":6,\"y\":26},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"}\",\"x\":6,\"y\":27},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"}\",\"x\":6,\"y\":28},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"}\",\"x\":6,\"y\":29},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"}\",\"x\":6,\"y\":30},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"}\",\"x\":6,\"y\":31},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"}\",\"x\":6,\"y\":32},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"}\",\"x\":6,\"y\":33},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"}\",\"x\":6,\"y\":34},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"}\",\"x\":6,\"y\":35},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\">\",\"x\":7,\"y\":0},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\">\",\"x\":7,\"y\":1},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\">\",\"x\":7,\"y\":2},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\">\",\"x\":7,\"y\":3},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\">\",\"x\":7,\"y\":4},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\">\",\"x\":7,\"y\":5},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\">\",\"x\":7,\"y\":6},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\">\",\"x\":7,\"y\":7},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\">\",\"x\":7,\"y\":8},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\">\",\"x\":7,\"y\":9},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\">\",\"x\":7,\"y\":10},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\">\",\"x\":7,\"y\":11},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\">\",\"x\":7,\"y\":12},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\">\",\"x\":7,\"y\":13},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\">\",\"x\":7,\"y\":14},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\">\",\"x\":7,\"y\":15},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\">\",\"x\":7,\"y\":16},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\">\",\"x\":7,\"y\":17},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\">\",\"x\":7,\"y\":18},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\">\",\"x\":7,\"y\":19},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\">\",\"x\":7,\"y\":20},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\">\",\"x\":7,\"y\":21},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\">\",\"x\":7,\"y\":22},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\">\",\"x\":7,\"y\":23},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\">\",\"x\":7,\"y\":24},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\">\",\"x\":7,\"y\":25},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\">\",\"x\":7,\"y\":26},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\">\",\"x\":7,\"y\":27},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\">\",\"x\":7,\"y\":28},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\">\",\"x\":7,\"y\":29},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\">\",\"x\":7,\"y\":30},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\">\",\"x\":7,\"y\":31},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\">\",\"x\":7,\"y\":32},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\">\",\"x\":7,\"y\":33},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\">\",\"x\":7,\"y\":34},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\">\",\"x\":7,\"y\":35}]},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('d083d851-ab26-4c19-97b1-011946a21603');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_bracket_scores(exploratory_prompts[:num_exploratory_prompts // 2], bracket_scores[:num_exploratory_prompts // 2, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>                            <div id=\"3e463303-299e-4e1c-bd55-a8b41a21c42d\" class=\"plotly-graph-div\" style=\"height:1080px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"3e463303-299e-4e1c-bd55-a8b41a21c42d\")) {                    Plotly.newPlot(                        \"3e463303-299e-4e1c-bd55-a8b41a21c42d\",                        [{\"coloraxis\":\"coloraxis\",\"name\":\"0\",\"x\":[\"(\",\"[\",\"{\",\"<\",\")\",\"]\",\"}\",\">\"],\"y\":[\"zip(enumerate(list(zip([1,3,65], [1, 2, 3], [4, 3], [1], list(np.zeros(4)))), [3, 4]\",\"zip(enumerate(list(zip([1,3,65], [1, 2, 3], [4, 3], [1], list(np.zeros(4)))), [3, 4])\",\"zip(enumerate(list(zip([1,3,65], list(np.zeros(4)))), [3, 4], {1: 2}.items()\",\"zip(enumerate(list(zip([1,3,65], list(np.zeros(4)))), [3, 4], {1: 2}.items())\",\"list())))).append(x\",\"list())))).append(x)\",\"px.imshow(to_numpy(tensor), ccm=0.0, ccs='RdBu', labels={'x':xaxis, 'y':yaxis}, **kwargs\",\"px.imshow(to_numpy(tensor), ccm=0.0, ccs='RdBu', labels={'x':xaxis, 'y':yaxis}, **kwargs)\",\"In the course our our analysis (which was long\",\"In the course our our analysis (which was long)\",\"He was eating a apple [sic\",\"He was eating a apple [sic]\",\"In the course our our analysis (which was long (though not too long\",\"In the course our our analysis (which was long (though not too long))\",\"def sieve(,num prime_list = 2[, 3]\",\"def sieve(,num prime_list = 2[, 3])\",\"defn line(tensor, renderer===None\",\"defn line(tensor, renderer===None)\",\"exploratory_dict = {'test': [3,} 5]\",\"exploratory_dict = {'test': [3,} 5\",\"exploratory_prompts = ['test'(]\",\"exploratory_prompts = ['test'(])\",\"def safasfd(oubefwef, vcewfec=afuasvfs\",\"def safasfd(oubefwef, vcewfec=afuasvfs)\",\"asdjhvauyrfsac = ['asdasdasd'\",\"asdjhvauyrfsac = ['asdasdasd']\",\"dfc = {'sdasd': 'casdasd'\",\"dfc = {'sdasd': 'casdasd'}\",\"<bwevzcxc\",\"<bwevzcxc>\",\"([]\",\"([])\",\"([({},[{()}])])\",\"([({},[{()}])]\",\"([({},[{()}])\",\"([({},[{()}]\"],\"z\":[[3.783132342505269e-05,5.1831357268383726e-05,3.6239005112292944e-06,1.3839829989592545e-05,0.9997289180755615,0.00014232848479878157,4.293161509849597e-06,1.7146552636404522e-05],[0.00012034500105073676,0.006113966461271048,0.0001571957691339776,0.00028586047119461,0.9904594421386719,0.0018653444712981582,0.00024657801259309053,0.0007510727737098932],[0.00011730697588063776,0.01523576769977808,1.5473602616111748e-05,5.639057053485885e-05,0.9842443466186523,0.00015284647815860808,0.00015316430653911084,2.4948129066615365e-05],[0.00015281829109881073,0.1519942283630371,0.0007371343090198934,0.0008431801106780767,0.8418084383010864,0.001006837235763669,0.0017511456971988082,0.0017064801650121808],[0.014876144006848335,0.07230646908283234,9.023873280966654e-05,0.00043510922114364803,0.9108191132545471,0.0009662336087785661,0.00014890721649862826,0.0003581260098144412],[0.0051384675316512585,0.012794174253940582,0.03802643343806267,0.039977528154850006,0.1775882989168167,0.4542897343635559,0.24731911718845367,0.024866294115781784],[0.00038896402111276984,0.002319883555173874,0.00012180537305539474,3.3715277822921053e-06,0.9966431856155396,9.020037396112457e-05,0.00041413403232581913,1.8808779714163393e-05],[0.010102849453687668,0.2312985062599182,0.012104828841984272,0.019382573664188385,0.12173610180616379,0.24417459964752197,0.3023645281791687,0.058835748583078384],[0.0065517486073076725,0.0008548697805963457,1.844005601014942e-05,1.8493101379135624e-05,0.9919562339782715,0.00011712627747328952,0.000348947593010962,0.00013441653572954237],[0.6288301348686218,0.312997043132782,0.002632362535223365,0.0043196901679039,0.023539774119853973,0.017418742179870605,0.007827507331967354,0.0024350425228476524],[6.686874257866293e-05,3.308882878627628e-05,2.900109166148468e-07,3.884119905706029e-06,0.0015944107435643673,0.9982820153236389,1.1906608051504008e-05,7.566005479020532e-06],[0.25786975026130676,0.6813380122184753,0.011278100311756134,0.006678693927824497,0.009518916718661785,0.02544407732784748,0.00020725687500089407,0.007665226701647043],[0.0008377173799090087,0.00018905229808297008,3.536929398251232e-07,1.1715917935362086e-05,0.9989267587661743,1.564390186103992e-05,2.6314271508454112e-06,1.6034118743846193e-05],[0.43765321373939514,0.3432966470718384,0.005631020292639732,0.006646838039159775,0.1296047866344452,0.05732715129852295,0.014347088523209095,0.005493395496159792],[0.0010961915832012892,0.0008884978014975786,0.0014319627080112696,0.00014321375056169927,0.9958769679069519,7.854343130020425e-05,1.7474278138251975e-05,0.0004673725343309343],[0.04543733596801758,0.18676896393299103,0.6103681325912476,0.002208962570875883,0.14834395051002502,0.0028436484280973673,8.011127647478133e-05,0.003949080128222704],[0.000407856801757589,0.00012212026922497898,2.238086744910106e-05,2.8089953048038296e-05,0.9993014931678772,3.0249711926444434e-05,5.189376315684058e-05,3.591752101783641e-05],[0.020307833328843117,0.0180380679666996,0.946365475654602,0.0024651954881846905,0.00954336579889059,0.00018066668417304754,0.00018273454043082893,0.002917018486186862],[0.000651473761536181,0.00218518846668303,0.0007920117932371795,0.0004919193452224135,0.00036502169677987695,0.0014075201470404863,0.993802011013031,0.0003049311926588416],[0.00040118215838447213,0.001543401274830103,0.0003487435169517994,6.373901851475239e-05,0.0019522365182638168,0.9482523202896118,0.04738938808441162,4.917227488476783e-05],[0.019063137471675873,0.02085445262491703,0.004997895564883947,0.01302140299230814,0.8924995064735413,0.021639592945575714,0.004554110113531351,0.023370057344436646],[0.03222385793924332,0.2542784810066223,0.12594890594482422,0.01861872524023056,0.09022998064756393,0.4255065619945526,0.04021997004747391,0.01297358050942421],[0.10262304544448853,0.009719982743263245,0.005174960941076279,0.00107120955362916,0.8768436312675476,0.0006661756779067218,0.0023837503977119923,0.0015173490392044187],[0.3586027920246124,0.10367269068956375,0.4815979599952698,0.009928400628268719,0.03084094077348709,0.0017966675804927945,0.0004982450045645237,0.013063127174973488],[0.0005793988239020109,0.0002459466049913317,0.0002185478515457362,0.000270027230726555,0.0013606586726382375,0.9937530755996704,0.002253646496683359,0.0013188573066145182],[0.04938633367419243,0.02634953148663044,0.018402474001049995,0.01031226385384798,0.7248654961585999,0.03882462903857231,0.11274494975805283,0.019114237278699875],[0.0002476288937032223,0.00014439245569519699,9.689645958133042e-05,5.863437763764523e-05,2.6521552172198426e-06,0.0002103250881191343,0.9992278218269348,1.1652907232928555e-05],[0.03885957598686218,0.2546241879463196,0.04334506019949913,0.04490484297275543,0.2025327831506729,0.3134497106075287,0.09001661092042923,0.012267201207578182],[0.004141136072576046,0.004385257605463266,0.010346543043851852,0.06446536630392075,0.0029017720371484756,0.007811599411070347,0.007348623126745224,0.8985996842384338],[0.04773643985390663,0.09959903359413147,0.10708749294281006,0.704691469669342,0.0067106555216014385,0.003139645094051957,0.011323846876621246,0.019711676985025406],[0.4754627048969269,0.02873150072991848,0.06368735432624817,0.032147862017154694,0.3862423598766327,0.0028335172683000565,0.002544278046116233,0.008349926210939884],[0.19811204075813293,0.15874968469142914,0.16583722829818726,0.03626523166894913,0.1950610876083374,0.12608762085437775,0.09477539360523224,0.025111518800258636],[0.04672913998365402,0.0735243707895279,0.057244788855314255,0.015802543610334396,0.31973886489868164,0.26840636134147644,0.19851729273796082,0.020036181434988976],[0.0169257503002882,0.0010254014050588012,0.010664409026503563,0.0015906929038465023,0.9408483505249023,0.010732650756835938,0.010102471336722374,0.00811032485216856],[0.004795885179191828,0.013731338083744049,0.008551940321922302,0.0017096914816647768,0.049973804503679276,0.9123013019561768,0.008360871113836765,0.0005751546705141664],[0.007474340032786131,0.0005488938186317682,0.00526469387114048,0.00045276148011907935,0.9615497589111328,0.0156177943572402,0.008211473003029823,0.0008801835356280208]],\"type\":\"heatmap\",\"xaxis\":\"x\",\"yaxis\":\"y\",\"hovertemplate\":\"Bracket: %{x}<br>y: %{y}<br>Conditional Probability: %{z}<extra></extra>\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"scaleanchor\":\"y\",\"constrain\":\"domain\",\"title\":{\"text\":\"Bracket\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"autorange\":\"reversed\",\"constrain\":\"domain\"},\"coloraxis\":{\"colorbar\":{\"title\":{\"text\":\"Conditional Probability\"}},\"colorscale\":[[0.0,\"rgb(247,251,255)\"],[0.125,\"rgb(222,235,247)\"],[0.25,\"rgb(198,219,239)\"],[0.375,\"rgb(158,202,225)\"],[0.5,\"rgb(107,174,214)\"],[0.625,\"rgb(66,146,198)\"],[0.75,\"rgb(33,113,181)\"],[0.875,\"rgb(8,81,156)\"],[1.0,\"rgb(8,48,107)\"]]},\"margin\":{\"t\":60},\"height\":1080,\"annotations\":[{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"(\",\"x\":0,\"y\":0},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"(\",\"x\":0,\"y\":1},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"(\",\"x\":0,\"y\":2},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"(\",\"x\":0,\"y\":3},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"(\",\"x\":0,\"y\":4},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"(\",\"x\":0,\"y\":5},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"(\",\"x\":0,\"y\":6},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"(\",\"x\":0,\"y\":7},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"(\",\"x\":0,\"y\":8},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"(\",\"x\":0,\"y\":9},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"(\",\"x\":0,\"y\":10},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"(\",\"x\":0,\"y\":11},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"(\",\"x\":0,\"y\":12},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"(\",\"x\":0,\"y\":13},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"(\",\"x\":0,\"y\":14},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"(\",\"x\":0,\"y\":15},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"(\",\"x\":0,\"y\":16},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"(\",\"x\":0,\"y\":17},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"(\",\"x\":0,\"y\":18},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"(\",\"x\":0,\"y\":19},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"(\",\"x\":0,\"y\":20},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"(\",\"x\":0,\"y\":21},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"(\",\"x\":0,\"y\":22},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"(\",\"x\":0,\"y\":23},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"(\",\"x\":0,\"y\":24},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"(\",\"x\":0,\"y\":25},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"(\",\"x\":0,\"y\":26},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"(\",\"x\":0,\"y\":27},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"(\",\"x\":0,\"y\":28},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"(\",\"x\":0,\"y\":29},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"(\",\"x\":0,\"y\":30},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"(\",\"x\":0,\"y\":31},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"(\",\"x\":0,\"y\":32},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"(\",\"x\":0,\"y\":33},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"(\",\"x\":0,\"y\":34},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"(\",\"x\":0,\"y\":35},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"[\",\"x\":1,\"y\":0},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"[\",\"x\":1,\"y\":1},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"[\",\"x\":1,\"y\":2},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"[\",\"x\":1,\"y\":3},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"[\",\"x\":1,\"y\":4},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"[\",\"x\":1,\"y\":5},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"[\",\"x\":1,\"y\":6},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"[\",\"x\":1,\"y\":7},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"[\",\"x\":1,\"y\":8},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"[\",\"x\":1,\"y\":9},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"[\",\"x\":1,\"y\":10},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"[\",\"x\":1,\"y\":11},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"[\",\"x\":1,\"y\":12},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"[\",\"x\":1,\"y\":13},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"[\",\"x\":1,\"y\":14},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"[\",\"x\":1,\"y\":15},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"[\",\"x\":1,\"y\":16},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"[\",\"x\":1,\"y\":17},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"[\",\"x\":1,\"y\":18},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"[\",\"x\":1,\"y\":19},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"[\",\"x\":1,\"y\":20},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"[\",\"x\":1,\"y\":21},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"[\",\"x\":1,\"y\":22},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"[\",\"x\":1,\"y\":23},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"[\",\"x\":1,\"y\":24},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"[\",\"x\":1,\"y\":25},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"[\",\"x\":1,\"y\":26},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"[\",\"x\":1,\"y\":27},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"[\",\"x\":1,\"y\":28},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"[\",\"x\":1,\"y\":29},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"[\",\"x\":1,\"y\":30},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"[\",\"x\":1,\"y\":31},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"[\",\"x\":1,\"y\":32},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"[\",\"x\":1,\"y\":33},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"[\",\"x\":1,\"y\":34},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"[\",\"x\":1,\"y\":35},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"{\",\"x\":2,\"y\":0},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"{\",\"x\":2,\"y\":1},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"{\",\"x\":2,\"y\":2},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"{\",\"x\":2,\"y\":3},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"{\",\"x\":2,\"y\":4},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"{\",\"x\":2,\"y\":5},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"{\",\"x\":2,\"y\":6},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"{\",\"x\":2,\"y\":7},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"{\",\"x\":2,\"y\":8},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"{\",\"x\":2,\"y\":9},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"{\",\"x\":2,\"y\":10},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"{\",\"x\":2,\"y\":11},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"{\",\"x\":2,\"y\":12},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"{\",\"x\":2,\"y\":13},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"{\",\"x\":2,\"y\":14},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"{\",\"x\":2,\"y\":15},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"{\",\"x\":2,\"y\":16},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"{\",\"x\":2,\"y\":17},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"{\",\"x\":2,\"y\":18},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"{\",\"x\":2,\"y\":19},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"{\",\"x\":2,\"y\":20},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"{\",\"x\":2,\"y\":21},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"{\",\"x\":2,\"y\":22},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"{\",\"x\":2,\"y\":23},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"{\",\"x\":2,\"y\":24},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"{\",\"x\":2,\"y\":25},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"{\",\"x\":2,\"y\":26},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"{\",\"x\":2,\"y\":27},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"{\",\"x\":2,\"y\":28},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"{\",\"x\":2,\"y\":29},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"{\",\"x\":2,\"y\":30},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"{\",\"x\":2,\"y\":31},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"{\",\"x\":2,\"y\":32},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"{\",\"x\":2,\"y\":33},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"{\",\"x\":2,\"y\":34},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"{\",\"x\":2,\"y\":35},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"<\",\"x\":3,\"y\":0},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"<\",\"x\":3,\"y\":1},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"<\",\"x\":3,\"y\":2},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"<\",\"x\":3,\"y\":3},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"<\",\"x\":3,\"y\":4},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"<\",\"x\":3,\"y\":5},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"<\",\"x\":3,\"y\":6},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"<\",\"x\":3,\"y\":7},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"<\",\"x\":3,\"y\":8},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"<\",\"x\":3,\"y\":9},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"<\",\"x\":3,\"y\":10},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"<\",\"x\":3,\"y\":11},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"<\",\"x\":3,\"y\":12},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"<\",\"x\":3,\"y\":13},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"<\",\"x\":3,\"y\":14},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"<\",\"x\":3,\"y\":15},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"<\",\"x\":3,\"y\":16},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"<\",\"x\":3,\"y\":17},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"<\",\"x\":3,\"y\":18},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"<\",\"x\":3,\"y\":19},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"<\",\"x\":3,\"y\":20},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"<\",\"x\":3,\"y\":21},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"<\",\"x\":3,\"y\":22},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"<\",\"x\":3,\"y\":23},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"<\",\"x\":3,\"y\":24},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"<\",\"x\":3,\"y\":25},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"<\",\"x\":3,\"y\":26},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"<\",\"x\":3,\"y\":27},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"<\",\"x\":3,\"y\":28},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"<\",\"x\":3,\"y\":29},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"<\",\"x\":3,\"y\":30},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"<\",\"x\":3,\"y\":31},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"<\",\"x\":3,\"y\":32},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"<\",\"x\":3,\"y\":33},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"<\",\"x\":3,\"y\":34},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"<\",\"x\":3,\"y\":35},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\")\",\"x\":4,\"y\":0},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\")\",\"x\":4,\"y\":1},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\")\",\"x\":4,\"y\":2},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\")\",\"x\":4,\"y\":3},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\")\",\"x\":4,\"y\":4},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\")\",\"x\":4,\"y\":5},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\")\",\"x\":4,\"y\":6},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\")\",\"x\":4,\"y\":7},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\")\",\"x\":4,\"y\":8},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\")\",\"x\":4,\"y\":9},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\")\",\"x\":4,\"y\":10},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\")\",\"x\":4,\"y\":11},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\")\",\"x\":4,\"y\":12},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\")\",\"x\":4,\"y\":13},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\")\",\"x\":4,\"y\":14},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\")\",\"x\":4,\"y\":15},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\")\",\"x\":4,\"y\":16},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\")\",\"x\":4,\"y\":17},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\")\",\"x\":4,\"y\":18},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\")\",\"x\":4,\"y\":19},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\")\",\"x\":4,\"y\":20},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\")\",\"x\":4,\"y\":21},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\")\",\"x\":4,\"y\":22},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\")\",\"x\":4,\"y\":23},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\")\",\"x\":4,\"y\":24},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\")\",\"x\":4,\"y\":25},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\")\",\"x\":4,\"y\":26},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\")\",\"x\":4,\"y\":27},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\")\",\"x\":4,\"y\":28},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\")\",\"x\":4,\"y\":29},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\")\",\"x\":4,\"y\":30},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\")\",\"x\":4,\"y\":31},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\")\",\"x\":4,\"y\":32},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\")\",\"x\":4,\"y\":33},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\")\",\"x\":4,\"y\":34},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\")\",\"x\":4,\"y\":35},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"]\",\"x\":5,\"y\":0},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"]\",\"x\":5,\"y\":1},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"]\",\"x\":5,\"y\":2},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"]\",\"x\":5,\"y\":3},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"]\",\"x\":5,\"y\":4},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"]\",\"x\":5,\"y\":5},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"]\",\"x\":5,\"y\":6},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"]\",\"x\":5,\"y\":7},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"]\",\"x\":5,\"y\":8},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"]\",\"x\":5,\"y\":9},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"]\",\"x\":5,\"y\":10},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"]\",\"x\":5,\"y\":11},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"]\",\"x\":5,\"y\":12},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"]\",\"x\":5,\"y\":13},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"]\",\"x\":5,\"y\":14},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"]\",\"x\":5,\"y\":15},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"]\",\"x\":5,\"y\":16},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"]\",\"x\":5,\"y\":17},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"]\",\"x\":5,\"y\":18},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"]\",\"x\":5,\"y\":19},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"]\",\"x\":5,\"y\":20},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"]\",\"x\":5,\"y\":21},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"]\",\"x\":5,\"y\":22},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"]\",\"x\":5,\"y\":23},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"]\",\"x\":5,\"y\":24},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"]\",\"x\":5,\"y\":25},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"]\",\"x\":5,\"y\":26},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"]\",\"x\":5,\"y\":27},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"]\",\"x\":5,\"y\":28},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"]\",\"x\":5,\"y\":29},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"]\",\"x\":5,\"y\":30},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"]\",\"x\":5,\"y\":31},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"]\",\"x\":5,\"y\":32},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"]\",\"x\":5,\"y\":33},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"]\",\"x\":5,\"y\":34},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"]\",\"x\":5,\"y\":35},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"}\",\"x\":6,\"y\":0},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"}\",\"x\":6,\"y\":1},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"}\",\"x\":6,\"y\":2},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"}\",\"x\":6,\"y\":3},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"}\",\"x\":6,\"y\":4},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"}\",\"x\":6,\"y\":5},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"}\",\"x\":6,\"y\":6},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"}\",\"x\":6,\"y\":7},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"}\",\"x\":6,\"y\":8},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"}\",\"x\":6,\"y\":9},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"}\",\"x\":6,\"y\":10},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"}\",\"x\":6,\"y\":11},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"}\",\"x\":6,\"y\":12},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"}\",\"x\":6,\"y\":13},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"}\",\"x\":6,\"y\":14},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"}\",\"x\":6,\"y\":15},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"}\",\"x\":6,\"y\":16},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"}\",\"x\":6,\"y\":17},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"}\",\"x\":6,\"y\":18},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"}\",\"x\":6,\"y\":19},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"}\",\"x\":6,\"y\":20},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"}\",\"x\":6,\"y\":21},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"}\",\"x\":6,\"y\":22},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"}\",\"x\":6,\"y\":23},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"}\",\"x\":6,\"y\":24},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"}\",\"x\":6,\"y\":25},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"}\",\"x\":6,\"y\":26},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"}\",\"x\":6,\"y\":27},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"}\",\"x\":6,\"y\":28},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"}\",\"x\":6,\"y\":29},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"}\",\"x\":6,\"y\":30},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"}\",\"x\":6,\"y\":31},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"}\",\"x\":6,\"y\":32},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"}\",\"x\":6,\"y\":33},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"}\",\"x\":6,\"y\":34},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"}\",\"x\":6,\"y\":35},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\">\",\"x\":7,\"y\":0},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\">\",\"x\":7,\"y\":1},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\">\",\"x\":7,\"y\":2},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\">\",\"x\":7,\"y\":3},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\">\",\"x\":7,\"y\":4},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\">\",\"x\":7,\"y\":5},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\">\",\"x\":7,\"y\":6},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\">\",\"x\":7,\"y\":7},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\">\",\"x\":7,\"y\":8},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\">\",\"x\":7,\"y\":9},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\">\",\"x\":7,\"y\":10},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\">\",\"x\":7,\"y\":11},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\">\",\"x\":7,\"y\":12},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\">\",\"x\":7,\"y\":13},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\">\",\"x\":7,\"y\":14},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\">\",\"x\":7,\"y\":15},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\">\",\"x\":7,\"y\":16},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\">\",\"x\":7,\"y\":17},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\">\",\"x\":7,\"y\":18},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\">\",\"x\":7,\"y\":19},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\">\",\"x\":7,\"y\":20},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\">\",\"x\":7,\"y\":21},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\">\",\"x\":7,\"y\":22},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\">\",\"x\":7,\"y\":23},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\">\",\"x\":7,\"y\":24},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\">\",\"x\":7,\"y\":25},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\">\",\"x\":7,\"y\":26},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\">\",\"x\":7,\"y\":27},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\">\",\"x\":7,\"y\":28},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\">\",\"x\":7,\"y\":29},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\">\",\"x\":7,\"y\":30},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\">\",\"x\":7,\"y\":31},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\">\",\"x\":7,\"y\":32},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\">\",\"x\":7,\"y\":33},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\">\",\"x\":7,\"y\":34},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\">\",\"x\":7,\"y\":35}]},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('3e463303-299e-4e1c-bd55-a8b41a21c42d');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_bracket_scores(exploratory_prompts[num_exploratory_prompts // 2:], bracket_scores[num_exploratory_prompts // 2:, :])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion\n",
    "\n",
    "- The model seems to do very well at predicting the correct closing bracket, and is robust to most things I've thrown at it.\n",
    "- One important case which occurs a few times though is when I'm looking to have the model predict `)` but it actually predicts `[`, with `)` being the second-most likely next bracket. I investigate this a little more below.\n",
    "- The fact that the model predicts `(` on `list())))).append(x` indicates that it is not confused by lots of closing brackets.\n",
    "- The model struggles a bit on the last prompts made purely of brackets and commas.\n",
    "- When the brackets are balanced, the model outputs vary a lot. Usually it predicts an opening bracket, though often spreading the probability over several types. Other times the probability is spread over both opening and closing brackets. And sometimes it predicts a closing bracket. \n",
    "    * It's not entirely clear what the model *should* predict in these cases. Oftentimes any kind of bracket would be inappropriate."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's think about the case where the model predicts `[` instead of `)`. I wouldn't say this is always wrong: it would be plausible to see a `[` in most of these cases, as a way of indexing some object, though usually this would be a bit weird.\n",
    "\n",
    "This observation raises a larger question about what exactly the task *is* and what the metric should be. The intuition is that a good model should be able to keep track of the open and closed brackets, and should prefer generating text which is *eventually* bracket-balanced. However, in the shorter term this may involve opening new brackets (after all, we wouldn't want to the model to be biased towards immediately closing all brackets it creates). I can think of the following ways of approaching this.\n",
    "1. The most direct way is to simply let the model continue to generate tokens, with the aim of seeing if the whole generated text is bracket-balanced and from there trying to understand how the model has done this. This would be a substantial undertaking, and beyond the scope of this small exploration.\n",
    "2. Another option is to focus only on the bracket type we care about. In this case, we'd only compare the prediction for `(` with `)`, and ignore the comparison with `[` and `]`. Of course there may still be instances where opening with `(` is a reasonable choice for the model to make so this doesn't completely eliminate the problem.\n",
    "3. The simplest way is to focus on clear-cut examples, where the only reasonable bracket is a closing one. I will go with this direction here, since it isolates more cleanly exactly what we want to investigate, which hopefully also makes the model behaviour more evident."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hypotheses\n",
    "\n",
    "How is GPT-Neo able to determine whether to close a bracket? Before I get my hands dirty with the model weights, I'm going briefly elaborate my thoughts for what might be going on."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- A basic component for this capability might be a 'bracket-counting' head. In this head certain tokens (perhaps those where some kind of bracket is likely as the next token, or just all tokens) attend to all the previous brackets. The opening bracket value vectors lie in an opposite direction to the closing bracket value vectors. This way, when we take the weighted sum, its projection onto the line determined by these opposing directions counts the value:\n",
    "```\n",
    "    (Number of opening brackets) - (Number of closing brackets)\n",
    "```\n",
    "- A simple way the transformer could use a bracket-counting head is by predicting an closing bracket if this number is positive and it is likely that the next token is some kind of bracket.\n",
    "- Such a simple head doesn't explain:\n",
    "    1. Why the model doesn't get confused by `list())))).append(x` (note that at `x` this count will be negative).\n",
    "    2. How the model can determine *which* bracket is appropriate.\n",
    "- Intuitively, in order to the deal with the first problem, the model needs some way of 'resetting' the count when it encounters the second `(`.\n",
    "- Here is one way this could be accomplished. There is a second bracket-counting head on a later layer, which works the same way except for the following modification. Any opening bracket which has a negative count from the first bracket-counting head gets the value vector which is the normal opening-bracket vector multiplied by the negative of the bracket count, plus one. This means that opening brackets appearing after a negatively balanced string reset the count, and counting can proceed as normal.\n",
    "- I can't think of a way to simplify this to a single head. Intuitively, the head which determines the final count already needs to have access to the bracket count computation, in order to determine when to reset. Perhaps there's a way to do it which doesn't involve counting.\n",
    "- To deal with the second token, the model needs some way of keeping track of the type of the most recent unclosed bracket. I haven't thought of a way this could work."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experimental setup\n",
    "\n",
    "Here I define the prompts which I will be testing, and the metric used to quantify model performance on them. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference prompts\n",
    "\n",
    "I choose the prompts according to following criteria.\n",
    "1. They should have the same number of tokens.\n",
    "2. The next token, if it is a bracket, should be clearly a closing one.\n",
    "3. Each should have a corrupted version, which has the same number of tokens, differs only slightly, but after which the model predicts something different (ideally an opening bracket).\n",
    "4. There should be a variety of kinds of prompt."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The motivations for these are as follows.\n",
    "1. This makes working with the next predicted token across all prompts simultaneously easier.\n",
    "2. Cases where there are more opening than closing brackets are more clear-cut.\n",
    "3. Later I would like to use activation patching as an interpretability tool. This requires a corrupted version.\n",
    "4. We want to find a mechanism by which the model robustly accomplishes the task, rather than one which might be specific to one kind of prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompts\n",
      "14 <|endoftext|>#def# line#(#data#_#t#ensor#,# rend#erer#='#four#'\n",
      "14 <|endoftext|>#model#.#dat#as#et#.#data# =# table#['#respond#er#'\n",
      "14 <|endoftext|>#{#b#(),# c#(),# d#(),# e#(),# f#(#x#)\n",
      "14 <|endoftext|>#<#template# id#='#named#_#car#riage#'# name#='#time#'\n",
      "14 <|endoftext|>#rend#erer#(#new#_#document#,# True#).#begin#('#small#'\n",
      "14 <|endoftext|>#[#factor#(#x#_#new#),# test#(),# inspect#(#p#)\n",
      "14 <|endoftext|>#spec#ification# =# {#'#<#xml#>#':# more#(#True#)\n",
      "14 <|endoftext|>#<#html# style#='#b#.#blue# {#color#:# blue#}#'\n",
      "\n",
      "Corrupted prompts\n",
      "14 <|endoftext|>#def# line#(#data#_#t#ensor#,# rend#erer#='#four#')\n",
      "14 <|endoftext|>#model#.#dat#as#et#.#data# =# table#['#respond#er#']\n",
      "14 <|endoftext|>#{#b#(),# c#(),# d#(),# e#(),# f#(#x#)}\n",
      "14 <|endoftext|>#<#template# id#='#named#_#car#riage#'# name#='#time#'>\n",
      "14 <|endoftext|>#rend#erer#(#new#_#document#,# True#).#begin#('#small#')\n",
      "14 <|endoftext|>#[#factor#(#x#_#new#),# test#(),# inspect#(#p#)]\n",
      "14 <|endoftext|>#spec#ification# =# {#'#<#xml#>#':# more#(#True#)}\n",
      "14 <|endoftext|>#<#html# style#='#b#.#blue# {#color#:# blue#}#'>\n"
     ]
    }
   ],
   "source": [
    "# The regular prompts and their answers\n",
    "prompts = [\n",
    "    \"def line(data_tensor, renderer='four'\",\n",
    "    \"model.dataset.data = table['responder'\",\n",
    "    \"{b(), c(), d(), e(), f(x)\",\n",
    "    \"<template id='named_carriage' name='time'\",\n",
    "    \"renderer(new_document, True).begin('small'\",\n",
    "    \"[factor(x_new), test(), inspect(p)\",\n",
    "    \"specification = {'<xml>': more(True)\",\n",
    "    \"<html style='b.blue {color: blue}'\",\n",
    "]\n",
    "answers_openness = [0] * len(prompts) # 1 if opening bracket\n",
    "answer_symbols = list(\")]}>)]}>\")\n",
    "\n",
    "# The corrupted prompts and their answers\n",
    "# Note: there aren't clear answers to what the exact symbol should be\n",
    "corrupted_prompts = [\n",
    "    \"def line(data_tensor, renderer='four')\",\n",
    "    \"model.dataset.data = table['responder']\",\n",
    "    \"{b(), c(), d(), e(), f(x)}\",\n",
    "    \"<template id='named_carriage' name='time'>\",\n",
    "    \"renderer(new_document, True).begin('small')\",\n",
    "    \"[factor(x_new), test(), inspect(p)]\",\n",
    "    \"specification = {'<xml>': more(True)}\",\n",
    "    \"<html style='b.blue {color: blue}'>\",\n",
    "]\n",
    "corrupted_answers_openness = [1] * len(corrupted_prompts) # 1 if opening bracket\n",
    "\n",
    "# Combine the non-corrupted and corrupted\n",
    "all_prompts = prompts + corrupted_prompts\n",
    "all_answers_openness = answers_openness + corrupted_answers_openness\n",
    "\n",
    "print (\"Prompts\")\n",
    "for prompt in prompts:\n",
    "    prompt_as_tokens = model.to_str_tokens(prompt)\n",
    "    print(len(prompt_as_tokens), \"#\".join(prompt_as_tokens))\n",
    "\n",
    "print()\n",
    "print (\"Corrupted prompts\")\n",
    "for prompt in corrupted_prompts:\n",
    "    prompt_as_tokens = model.to_str_tokens(prompt)\n",
    "    print(len(prompt_as_tokens), \"#\".join(prompt_as_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt_tokens: torch.Size([8, 14])\n",
      "corrupted_prompt_tokens: torch.Size([8, 14])\n",
      "all_prompt_tokens: torch.Size([16, 14])\n"
     ]
    }
   ],
   "source": [
    "# Convert all the prompts to tokens, padding to make them the same length\n",
    "all_prompt_tokens = model.to_tokens(all_prompts).to(device)\n",
    "prompt_tokens = all_prompt_tokens[:len(prompts), :]\n",
    "corrupted_prompt_tokens = all_prompt_tokens[len(prompts):, :]\n",
    "\n",
    "print(\"prompt_tokens:\", prompt_tokens.shape)\n",
    "print(\"corrupted_prompt_tokens:\", corrupted_prompt_tokens.shape)\n",
    "print(\"all_prompt_tokens:\", all_prompt_tokens.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visualise the model performance on the prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>                            <div id=\"36d2e2f3-4369-48d4-b84d-f7685de05d0e\" class=\"plotly-graph-div\" style=\"height:640px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"36d2e2f3-4369-48d4-b84d-f7685de05d0e\")) {                    Plotly.newPlot(                        \"36d2e2f3-4369-48d4-b84d-f7685de05d0e\",                        [{\"coloraxis\":\"coloraxis\",\"name\":\"0\",\"x\":[\"(\",\"[\",\"{\",\"<\",\")\",\"]\",\"}\",\">\"],\"y\":[\"def line(data_tensor, renderer='four'\",\"model.dataset.data = table['responder'\",\"{b(), c(), d(), e(), f(x)\",\"<template id='named_carriage' name='time'\",\"renderer(new_document, True).begin('small'\",\"[factor(x_new), test(), inspect(p)\",\"specification = {'<xml>': more(True)\",\"<html style='b.blue {color: blue}'\",\"def line(data_tensor, renderer='four')\",\"model.dataset.data = table['responder']\",\"{b(), c(), d(), e(), f(x)}\",\"<template id='named_carriage' name='time'>\",\"renderer(new_document, True).begin('small')\",\"[factor(x_new), test(), inspect(p)]\",\"specification = {'<xml>': more(True)}\",\"<html style='b.blue {color: blue}'>\"],\"z\":[[4.0845909097697586e-05,0.000583446875680238,1.2041942682117224e-05,8.239389899244998e-06,0.9991393089294434,2.1074263258924475e-06,3.2315720090991817e-06,0.00021068696514703333],[1.1182510206708685e-05,1.6669526303303428e-05,1.987591531360522e-06,2.4423228751402348e-05,1.910684659378603e-06,0.9997237324714661,0.00019499423797242343,2.5355644538649358e-05],[0.002138939220458269,0.0007400010945275426,0.0054753185249865055,0.019648006185889244,0.00027858209796249866,0.0003157307510264218,0.9585424661636353,0.012861157767474651],[0.0010331079829484224,0.004348312970250845,0.004267917014658451,0.0045164539478719234,0.0006564196082763374,0.00045295903692021966,0.00025719363475218415,0.9844675660133362],[0.006689833011478186,0.0032863502856343985,0.0007558726356364787,0.0017512092599645257,0.9740374684333801,0.0019086762331426144,0.0014541835989803076,0.010116149671375751],[0.0016786952037364244,0.0022457106970250607,0.007600426208227873,0.004531071521341801,0.013487800024449825,0.960982620716095,0.001907364116050303,0.0075660827569663525],[0.0012869347119703889,0.001971310004591942,0.014029732905328274,0.003349706530570984,4.134665687161032e-06,7.910265412647277e-05,0.978911280632019,0.0003677530912682414],[0.0002617583959363401,0.000597211706917733,0.0006201667711138725,0.002838436746969819,2.3110736947273836e-05,5.83438049943652e-05,0.00028315838426351547,0.995317816734314],[0.022926494479179382,0.3047207295894623,0.6372870206832886,0.0005036972579546273,0.03238394483923912,0.00036158208968117833,7.979639485711232e-05,0.0017372311558574438],[0.10054793953895569,0.4974648356437683,0.03890956938266754,0.04471215233206749,0.19859470427036285,0.046642571687698364,0.06460931897163391,0.008518622256815434],[0.1256423443555832,0.09267544746398926,0.19473883509635925,0.12798269093036652,0.23578301072120667,0.08953504264354706,0.0554659478366375,0.07817614078521729],[0.0032398421317338943,0.005509546957910061,0.7559093236923218,0.23360438644886017,0.000465273653389886,0.00020666010095737875,0.000719101692084223,0.0003460742882452905],[0.049847111105918884,0.08086181432008743,0.21990390121936798,0.07810601592063904,0.27875152230262756,0.05998514965176582,0.2074015885591507,0.02514275349676609],[0.1636640578508377,0.009415828622877598,0.20234617590904236,0.03084702417254448,0.34799134731292725,0.1194072961807251,0.06983835250139236,0.05649033933877945],[0.018467478454113007,0.016953861340880394,0.04200029745697975,0.2677575945854187,0.10177432000637054,0.09709315001964569,0.4207594692707062,0.03519400954246521],[0.006267456337809563,0.0010978813515976071,0.14616267383098602,0.8405607342720032,0.002107215579599142,0.0001774320990080014,0.002876672660931945,0.000750187668018043]],\"type\":\"heatmap\",\"xaxis\":\"x\",\"yaxis\":\"y\",\"hovertemplate\":\"Bracket: %{x}<br>y: %{y}<br>Conditional Probability: %{z}<extra></extra>\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"scaleanchor\":\"y\",\"constrain\":\"domain\",\"title\":{\"text\":\"Bracket\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"autorange\":\"reversed\",\"constrain\":\"domain\"},\"coloraxis\":{\"colorbar\":{\"title\":{\"text\":\"Conditional Probability\"}},\"colorscale\":[[0.0,\"rgb(247,251,255)\"],[0.125,\"rgb(222,235,247)\"],[0.25,\"rgb(198,219,239)\"],[0.375,\"rgb(158,202,225)\"],[0.5,\"rgb(107,174,214)\"],[0.625,\"rgb(66,146,198)\"],[0.75,\"rgb(33,113,181)\"],[0.875,\"rgb(8,81,156)\"],[1.0,\"rgb(8,48,107)\"]]},\"margin\":{\"t\":60},\"height\":640,\"annotations\":[{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"(\",\"x\":0,\"y\":0},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"(\",\"x\":0,\"y\":1},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"(\",\"x\":0,\"y\":2},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"(\",\"x\":0,\"y\":3},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"(\",\"x\":0,\"y\":4},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"(\",\"x\":0,\"y\":5},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"(\",\"x\":0,\"y\":6},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"(\",\"x\":0,\"y\":7},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"(\",\"x\":0,\"y\":8},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"(\",\"x\":0,\"y\":9},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"(\",\"x\":0,\"y\":10},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"(\",\"x\":0,\"y\":11},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"(\",\"x\":0,\"y\":12},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"(\",\"x\":0,\"y\":13},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"(\",\"x\":0,\"y\":14},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"(\",\"x\":0,\"y\":15},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"[\",\"x\":1,\"y\":0},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"[\",\"x\":1,\"y\":1},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"[\",\"x\":1,\"y\":2},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"[\",\"x\":1,\"y\":3},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"[\",\"x\":1,\"y\":4},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"[\",\"x\":1,\"y\":5},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"[\",\"x\":1,\"y\":6},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"[\",\"x\":1,\"y\":7},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"[\",\"x\":1,\"y\":8},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"[\",\"x\":1,\"y\":9},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"[\",\"x\":1,\"y\":10},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"[\",\"x\":1,\"y\":11},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"[\",\"x\":1,\"y\":12},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"[\",\"x\":1,\"y\":13},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"[\",\"x\":1,\"y\":14},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"[\",\"x\":1,\"y\":15},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"{\",\"x\":2,\"y\":0},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"{\",\"x\":2,\"y\":1},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"{\",\"x\":2,\"y\":2},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"{\",\"x\":2,\"y\":3},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"{\",\"x\":2,\"y\":4},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"{\",\"x\":2,\"y\":5},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"{\",\"x\":2,\"y\":6},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"{\",\"x\":2,\"y\":7},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"{\",\"x\":2,\"y\":8},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"{\",\"x\":2,\"y\":9},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"{\",\"x\":2,\"y\":10},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"{\",\"x\":2,\"y\":11},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"{\",\"x\":2,\"y\":12},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"{\",\"x\":2,\"y\":13},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"{\",\"x\":2,\"y\":14},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"{\",\"x\":2,\"y\":15},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"<\",\"x\":3,\"y\":0},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"<\",\"x\":3,\"y\":1},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"<\",\"x\":3,\"y\":2},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"<\",\"x\":3,\"y\":3},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"<\",\"x\":3,\"y\":4},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"<\",\"x\":3,\"y\":5},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"<\",\"x\":3,\"y\":6},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"<\",\"x\":3,\"y\":7},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"<\",\"x\":3,\"y\":8},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"<\",\"x\":3,\"y\":9},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"<\",\"x\":3,\"y\":10},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"<\",\"x\":3,\"y\":11},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"<\",\"x\":3,\"y\":12},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"<\",\"x\":3,\"y\":13},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"<\",\"x\":3,\"y\":14},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"<\",\"x\":3,\"y\":15},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\")\",\"x\":4,\"y\":0},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\")\",\"x\":4,\"y\":1},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\")\",\"x\":4,\"y\":2},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\")\",\"x\":4,\"y\":3},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\")\",\"x\":4,\"y\":4},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\")\",\"x\":4,\"y\":5},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\")\",\"x\":4,\"y\":6},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\")\",\"x\":4,\"y\":7},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\")\",\"x\":4,\"y\":8},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\")\",\"x\":4,\"y\":9},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\")\",\"x\":4,\"y\":10},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\")\",\"x\":4,\"y\":11},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\")\",\"x\":4,\"y\":12},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\")\",\"x\":4,\"y\":13},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\")\",\"x\":4,\"y\":14},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\")\",\"x\":4,\"y\":15},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"]\",\"x\":5,\"y\":0},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"]\",\"x\":5,\"y\":1},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"]\",\"x\":5,\"y\":2},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"]\",\"x\":5,\"y\":3},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"]\",\"x\":5,\"y\":4},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"]\",\"x\":5,\"y\":5},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"]\",\"x\":5,\"y\":6},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"]\",\"x\":5,\"y\":7},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"]\",\"x\":5,\"y\":8},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"]\",\"x\":5,\"y\":9},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"]\",\"x\":5,\"y\":10},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"]\",\"x\":5,\"y\":11},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"]\",\"x\":5,\"y\":12},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"]\",\"x\":5,\"y\":13},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"]\",\"x\":5,\"y\":14},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"]\",\"x\":5,\"y\":15},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"}\",\"x\":6,\"y\":0},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"}\",\"x\":6,\"y\":1},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"}\",\"x\":6,\"y\":2},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"}\",\"x\":6,\"y\":3},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"}\",\"x\":6,\"y\":4},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"}\",\"x\":6,\"y\":5},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"}\",\"x\":6,\"y\":6},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"}\",\"x\":6,\"y\":7},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"}\",\"x\":6,\"y\":8},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"}\",\"x\":6,\"y\":9},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"}\",\"x\":6,\"y\":10},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"}\",\"x\":6,\"y\":11},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"}\",\"x\":6,\"y\":12},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"}\",\"x\":6,\"y\":13},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"}\",\"x\":6,\"y\":14},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\"}\",\"x\":6,\"y\":15},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\">\",\"x\":7,\"y\":0},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\">\",\"x\":7,\"y\":1},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\">\",\"x\":7,\"y\":2},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\">\",\"x\":7,\"y\":3},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\">\",\"x\":7,\"y\":4},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\">\",\"x\":7,\"y\":5},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\">\",\"x\":7,\"y\":6},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\">\",\"x\":7,\"y\":7},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\">\",\"x\":7,\"y\":8},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\">\",\"x\":7,\"y\":9},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\">\",\"x\":7,\"y\":10},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\">\",\"x\":7,\"y\":11},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\">\",\"x\":7,\"y\":12},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\">\",\"x\":7,\"y\":13},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\">\",\"x\":7,\"y\":14},{\"font\":{\"color\":\"orange\"},\"showarrow\":false,\"text\":\">\",\"x\":7,\"y\":15}]},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('36d2e2f3-4369-48d4-b84d-f7685de05d0e');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bracket_scores = compute_bracket_scores(all_prompt_tokens)\n",
    "display_bracket_scores(all_prompts, bracket_scores, height_scale=40)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics\n",
    "\n",
    "I now define the metrics used to evaluate the model performance. The first metric measures the success at predicting openness or closedness of the bracket. The second measures in addition how well the model predicts the actual token. Both use average logit difference."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the first metric, we take the sum of the logits for open bracket tokens and find the difference with the sum of the logits for closed bracket tokens. When we expect the answer to be an open bracket, the metric is the first of these quantities take away the second. When we expect a closed bracket, it's the other way around."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def openness_metric(\n",
    "    logits: torch.Tensor, answers_openness: list, per_prompt=False\n",
    ") -> torch.Tensor:\n",
    "    \"\"\"Computes the average difference between the open and closed logits\"\"\"\n",
    "\n",
    "    # Turn the answer openness into a sign tensor\n",
    "    answers_openness = torch.tensor(answers_openness, device=device)\n",
    "    answers_openness_sign = torch.sign(2 * answers_openness - 1)\n",
    "\n",
    "    # Select the final open and closed bracket logits\n",
    "    open_bracket_logits = logits[:, -1, open_bracket_tokens]\n",
    "    closed_bracket_logits = logits[:, -1, closed_bracket_tokens]\n",
    "\n",
    "    # Sum up the logits for open and closed brackets\n",
    "    open_bracket_logits_sum = open_bracket_logits.sum(dim=-1)\n",
    "    closed_bracket_logits_sum = closed_bracket_logits.sum(dim=-1)\n",
    "\n",
    "    # Compute the difference signed by the answer openness\n",
    "    bracket_logit_diff = open_bracket_logits_sum - closed_bracket_logits_sum\n",
    "    bracket_logit_diff = bracket_logit_diff * answers_openness_sign\n",
    "\n",
    "    if per_prompt:\n",
    "        return bracket_logit_diff\n",
    "    else:\n",
    "        return bracket_logit_diff.mean()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test on the reference prompts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 101.9118,  332.5992,    6.9850,  223.4595,  227.4698,  295.8047,\n",
      "        -162.3903,  132.8040])\n"
     ]
    }
   ],
   "source": [
    "logits = model(prompt_tokens, return_type=\"logits\")\n",
    "openness_metrics = openness_metric(logits, answers_openness, per_prompt=True)\n",
    "\n",
    "print(openness_metrics)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's a fair bit of variance in the metric for the reference prompts, even though the conditional probabilities all clearly favour one option. This is because:\n",
    "1. We're looking at logits not probabilities (i.e. they are not 'normalised' by the softmax).\n",
    "2. Earlier we consider the conditional probability, which has to sum to one over all brackets. It could be that the model predicts a non-bracket higher than any bracket."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next I define the metric for how well the model predicts the correct bracket. There are several ways of doing this. Here I take the sum of the logits corresponding to the correct bracket, and take away the mean of the sum of the logits for the rest of the brackets.\n",
    "\n",
    "The motivation for this is as follows. We want the metric to be linear in the logits, because this makes later analysis easier. During training the optimiser tries to minimise the cross entropy loss of the softmax of the logits. If $\\{x_i\\}$ is the set of all logits, and $x_{\\text{true}}$ is the logit for the true next token, this corresponds to maximising:\n",
    "$$\n",
    "    x_{\\text{true}} - \\log \\left(\\sum_i \\exp(x_i) \\right)\n",
    "$$\n",
    "If we want to focus on just getting the correct bracket, we can see this as maximising:\n",
    "$$\n",
    "    x_{\\text{true}} - \\log \\left(\\sum_{i \\in B} \\exp(x_i) \\right)\n",
    "$$\n",
    "where $B$ is the set of logits corresponding to brackets.\n",
    "\n",
    "How do approximate this with a linear function? In general, logsumexp is not very linear, but approximating it with the mean seems ok for the purposes of making a metric.\n",
    "\n",
    "Now the above is a bit of a simplification, since there isn't a 'true' next bracket token, because there are many tokens whose string representation starts with the same token. So instead we combine all logits whose tokens begin with the same bracket, and thus arrive at our metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bracket_symbol_metric(\n",
    "    logits: torch.Tensor, answer_symbols: list, per_prompt=False\n",
    ") -> torch.Tensor:\n",
    "    \"\"\"Compute the difference from the answer bracket logit to all others\"\"\"\n",
    "\n",
    "    batch_size = logits.shape[0]\n",
    "\n",
    "    # Sum the logits corresponding to each bracket\n",
    "    sum_per_bracket = torch.zeros((batch_size, num_brackets))\n",
    "    for i, tokens in enumerate(bracket_tokens.values()):\n",
    "        sum_per_bracket[:, i] = logits[:, -1, tokens].sum(dim=-1)\n",
    "\n",
    "    # Turn the answers_symbol list into a tensor for indexing `sum_per_bracket`\n",
    "    answer_symbol_indices = [brackets_flat.index(bracket) for bracket in answer_symbols]\n",
    "    answer_symbol_indices = torch.tensor(answer_symbol_indices)\n",
    "    answer_symbol_indices = answer_symbol_indices.reshape((batch_size, 1))\n",
    "\n",
    "    # Compute the logits difference from the answer to the sum of the other\n",
    "    # brackets\n",
    "    answer_logits = sum_per_bracket.gather(dim=-1, index=answer_symbol_indices)\n",
    "    answer_logits = answer_logits.squeeze()\n",
    "    logit_diff = 2 * answer_logits - sum_per_bracket.mean(dim=-1)\n",
    "\n",
    "    if per_prompt:\n",
    "        return logit_diff\n",
    "    else:\n",
    "        return logit_diff.mean()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check this metric the with reference prompts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([585.3561, 648.4344, 364.9975, 245.7553, 678.2637, 472.1611, 374.2183,\n",
       "        320.5639])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bracket_symbol_metric(logits, answer_symbols, per_prompt=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compare with some random incorrect answers, to make sure the metric is doing what we want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-36.8596,  89.3942, 149.0051, 199.3244, -38.3681, 345.0772, 142.3415,\n",
       "         77.5222])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bracket_symbol_metric(logits, list(\"<[>){)[]\"), per_prompt=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Direct logit attribution\n",
    "\n",
    "In this section I investigate the model using the 'direct logit attribution' method, which looks at how different parts of the model directly affect the output logits.\n",
    "\n",
    "Much of this section is copied directly from the [Exploratory Analysis notebook](https://neelnanda.io/exploratory-analysis-demo). See the 'Direct Logit Attribution' section in that notebook for more details on the techniques."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a first pass, I will make the following simplifications.\n",
    "1. I will focus solely on the task determining if the next bracket should be opening or closing.\n",
    "2. Rather than comparing all tokens beginning with a bracket across all bracket types, I will fix a bracket type per prompt and compare only the tokens corresponding to the opening and closing versions. This is to be able to talk about residual directions, looking at the logit difference between the two possible tokens."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first add some wrong answers then tokenise everything."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_wrong_symbols = list(\"([{<([{<\")\n",
    "\n",
    "# Tokenise everything\n",
    "answer_tokens = [model.to_single_token(b) for b in answer_symbols]\n",
    "answer_wrong_tokens = [model.to_single_token(b) for b in answer_wrong_symbols]\n",
    "answer_tokens = torch.tensor(answer_tokens)\n",
    "answer_wrong_tokens = torch.tensor(answer_wrong_tokens)\n",
    "answer_both_tokens = torch.stack((answer_tokens, answer_wrong_tokens)).T"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's run the model and cache the intermediate activations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_logits, cache = model.run_with_cache(prompt_tokens)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now compute the directions in the residual stream corresponding to moving from the wrong answer to the right one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer residual directions shape: torch.Size([8, 2, 768])\n",
      "Logit difference directions shape: torch.Size([8, 768])\n"
     ]
    }
   ],
   "source": [
    "answer_residual_directions = model.tokens_to_residual_directions(answer_both_tokens)\n",
    "print(\"Answer residual directions shape:\", answer_residual_directions.shape)\n",
    "logit_diff_directions = (\n",
    "    answer_residual_directions[:, 0] - answer_residual_directions[:, 1]\n",
    ")\n",
    "print(\"Logit difference directions shape:\", logit_diff_directions.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test to see if this works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final residual stream shape: torch.Size([8, 14, 768])\n",
      "Calculated average logit diff: 3.5070555210113525\n",
      "Original logit difference: 3.8240890502929688\n"
     ]
    }
   ],
   "source": [
    "# cache syntax - resid_post is the residual stream at the end of the layer, -1\n",
    "# gets the final layer. The general syntax is [activation_name, layer_index,\n",
    "# sub_layer_type].\n",
    "final_residual_stream = cache[\"resid_post\", -1]\n",
    "print(\"Final residual stream shape:\", final_residual_stream.shape)\n",
    "final_token_residual_stream = final_residual_stream[:, -1, :]\n",
    "# Apply LayerNorm scaling. pos_slice is the subset of the positions we take -\n",
    "# here the final token of each prompt\n",
    "scaled_final_token_residual_stream = cache.apply_ln_to_stack(\n",
    "    final_token_residual_stream, layer=-1, pos_slice=-1\n",
    ")\n",
    "\n",
    "# Get the original logit difference\n",
    "final_logits = original_logits[:, -1, :]\n",
    "answer_logits = final_logits.gather(dim=-1, index=answer_both_tokens.to(device))\n",
    "original_average_logit_diff = answer_logits[:, 0] - answer_logits[:, 1]\n",
    "original_average_logit_diff = original_average_logit_diff.mean()\n",
    "\n",
    "average_logit_diff = einsum(\n",
    "    \"batch d_model, batch d_model -> \",\n",
    "    scaled_final_token_residual_stream,\n",
    "    logit_diff_directions,\n",
    ") / len(prompts)\n",
    "print(\"Calculated average logit diff:\", average_logit_diff.item())\n",
    "print(\"Original logit difference:\", original_average_logit_diff.item())\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logit lens"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we look at the residual stream after each layer calculate the logit difference from that. This gives an idea of when the model starts being able to do the task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def residual_stack_to_logit_diff(\n",
    "    residual_stack: Float[torch.Tensor, \"components batch d_model\"],\n",
    "    cache: ActivationCache,\n",
    ") -> float:\n",
    "    scaled_residual_stack = cache.apply_ln_to_stack(\n",
    "        residual_stack, layer=-1, pos_slice=-1\n",
    "    )\n",
    "    return einsum(\n",
    "        \"... batch d_model, batch d_model -> ...\",\n",
    "        scaled_residual_stack,\n",
    "        logit_diff_directions,\n",
    "    ) / len(prompts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([25, 8, 768])\n",
      "torch.Size([25])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>                            <div id=\"7a0a34e8-ee88-4a9e-9593-617087740d80\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"7a0a34e8-ee88-4a9e-9593-617087740d80\")) {                    Plotly.newPlot(                        \"7a0a34e8-ee88-4a9e-9593-617087740d80\",                        [{\"hovertemplate\":\"<b>%{hovertext}</b><br><br>x=%{x}<br>y=%{y}<extra></extra>\",\"hovertext\":[\"0_pre\",\"0_mid\",\"1_pre\",\"1_mid\",\"2_pre\",\"2_mid\",\"3_pre\",\"3_mid\",\"4_pre\",\"4_mid\",\"5_pre\",\"5_mid\",\"6_pre\",\"6_mid\",\"7_pre\",\"7_mid\",\"8_pre\",\"8_mid\",\"9_pre\",\"9_mid\",\"10_pre\",\"10_mid\",\"11_pre\",\"11_mid\",\"final_post\"],\"legendgroup\":\"\",\"line\":{\"color\":\"#636efa\",\"dash\":\"solid\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines\",\"name\":\"\",\"orientation\":\"v\",\"showlegend\":false,\"x\":[0.0,0.5,1.0,1.5,2.0,2.5,3.0,3.5,4.0,4.5,5.0,5.5,6.0,6.5,7.0,7.5,8.0,8.5,9.0,9.5,10.0,10.5,11.0,11.5,12.0],\"xaxis\":\"x\",\"y\":[0.1326475888490677,-1.0357563495635986,-2.0593316555023193,-2.940925121307373,-3.6660237312316895,-7.584017753601074,-7.596715927124023,-6.966047286987305,-7.235817909240723,-6.579507350921631,-6.8386125564575195,1.0659483671188354,0.37148529291152954,0.8216102123260498,0.8474677801132202,1.4055311679840088,1.328263759613037,1.4906032085418701,3.0765366554260254,6.096038818359375,5.654181003570557,4.404540061950684,5.445803165435791,3.6348345279693604,3.5070555210113525],\"yaxis\":\"y\",\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"x\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"y\"}},\"legend\":{\"tracegroupgap\":0},\"title\":{\"text\":\"Logit Difference From Accumulate Residual Stream\"}},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('7a0a34e8-ee88-4a9e-9593-617087740d80');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "accumulated_residual, labels = cache.accumulated_resid(\n",
    "    layer=-1, incl_mid=True, pos_slice=-1, return_labels=True\n",
    ")\n",
    "print(accumulated_residual.shape)\n",
    "logit_lens_logit_diffs = residual_stack_to_logit_diff(accumulated_residual, cache)\n",
    "print(logit_lens_logit_diffs.shape)\n",
    "line(\n",
    "    logit_lens_logit_diffs,\n",
    "    x=np.arange(model.cfg.n_layers * 2 + 1) / 2,\n",
    "    hover_name=labels,\n",
    "    title=\"Logit Difference From Accumulate Residual Stream\",\n",
    ")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interestingly, for the first six layers the model actually gets worse at the task. In layer 5 the model performance jumps back up to around baseline performance, and stays there until layers 8 and 9 where it achieves best performance. Afterwards the performance decreases a little bit.\n",
    "\n",
    "Here are my provisional thoughts on what might be happening.\n",
    "- It could be that solving the task requires intermediate computation steps, and during these steps the model predicts the wrong token (at least on the prompts on which we're testing).\n",
    "- Alternatively, the initial dip in performance might be unrelated to the task. Perhaps the model doesn't try to figure out bracket balance until the later layers. Earlier on it might be doing other things with the logit directions; in other words there's some superposition going on, and the different superposed features are computed at different stages of the model.\n",
    "- The final decrease in performance might be because the sample of prompts is not representative enough. Perhaps in order to get the best performance across all bracket matching tasks (weighted by the data distribution), the optimiser decided to reduce performance on the current set of prompts in favour of others. In other words, while we might see decreasing performance on these prompts in the last layers, on others might still be low at layer 9 and continue increasing.\n",
    "- Another possibility is that the current metric for performance is too crude: it only focuses on the difference between two tokens. Could it be for example that in the later layers the model tries to decide which of the tokens beginning with the correct bracket is most appropriate? "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Layer attribution\n",
    "\n",
    "We now repeat the above analysis but per layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>                            <div id=\"2a9cf3e8-07cb-4c4c-ba4f-1e29f7b2688f\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"2a9cf3e8-07cb-4c4c-ba4f-1e29f7b2688f\")) {                    Plotly.newPlot(                        \"2a9cf3e8-07cb-4c4c-ba4f-1e29f7b2688f\",                        [{\"hovertemplate\":\"<b>%{hovertext}</b><br><br>x=%{x}<br>y=%{y}<extra></extra>\",\"hovertext\":[\"embed\",\"pos_embed\",\"0_attn_out\",\"0_mlp_out\",\"1_attn_out\",\"1_mlp_out\",\"2_attn_out\",\"2_mlp_out\",\"3_attn_out\",\"3_mlp_out\",\"4_attn_out\",\"4_mlp_out\",\"5_attn_out\",\"5_mlp_out\",\"6_attn_out\",\"6_mlp_out\",\"7_attn_out\",\"7_mlp_out\",\"8_attn_out\",\"8_mlp_out\",\"9_attn_out\",\"9_mlp_out\",\"10_attn_out\",\"10_mlp_out\",\"11_attn_out\",\"11_mlp_out\"],\"legendgroup\":\"\",\"line\":{\"color\":\"#636efa\",\"dash\":\"solid\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines\",\"name\":\"\",\"orientation\":\"v\",\"showlegend\":false,\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25],\"xaxis\":\"x\",\"y\":[0.1380680352449417,-0.0054205008782446384,-1.1684043407440186,-1.023576021194458,-0.8815919160842896,-0.7250982522964478,-3.9179940223693848,-0.012698769569396973,0.6306684017181396,-0.2697727680206299,0.6563105583190918,-0.25910326838493347,7.904561996459961,-0.6944642066955566,0.4501255452632904,0.025857575237751007,0.558063268661499,-0.07726666331291199,0.1623375117778778,1.5859346389770508,3.0195040702819824,-0.4418591856956482,-1.2496426105499268,1.0412615537643433,-1.8109644651412964,-0.12777948379516602],\"yaxis\":\"y\",\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"x\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"y\"}},\"legend\":{\"tracegroupgap\":0},\"title\":{\"text\":\"Logit Difference From Each Layer\"}},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('2a9cf3e8-07cb-4c4c-ba4f-1e29f7b2688f');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "per_layer_residual, labels = cache.decompose_resid(\n",
    "    layer=-1, pos_slice=-1, return_labels=True\n",
    ")\n",
    "per_layer_logit_diffs = residual_stack_to_logit_diff(per_layer_residual, cache)\n",
    "line(per_layer_logit_diffs, hover_name=labels, title=\"Logit Difference From Each Layer\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Layer yields a big improvement in performance, as observed before. We can now see that this is entirely due to the attention layer.\n",
    "- In fact, up to layer 7 almost all of the performance changes (up and down) can be attributed to attention.\n",
    "- The biggest decrease in performance comes from the layer-2 attention.\n",
    "- However, the MLP layers do play a role in later layers.\n",
    "- The ultimate gain in performance in layers 8 and 9 can be attributed to the layer-8 MLP and the layer-9 attention.\n",
    "    * A tentative conclusion might be that the main way the model solves the task is by an MLP followed by an attention layer.\n",
    "- The final decrease in performance can mostly be attributed to the attention layers."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Head attribution\n",
    "\n",
    "Let's break things down further by looking at the individual heads in the attention layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tried to stack head results when they weren't cached. Computing head results now\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>                            <div id=\"f3d43306-a419-4086-8ea3-23187e75e554\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"f3d43306-a419-4086-8ea3-23187e75e554\")) {                    Plotly.newPlot(                        \"f3d43306-a419-4086-8ea3-23187e75e554\",                        [{\"coloraxis\":\"coloraxis\",\"name\":\"0\",\"z\":[[-0.12933094799518585,-0.6222943067550659,-0.4824504554271698,-0.44885796308517456,-0.032292768359184265,0.19880644977092743,-0.6575671434402466,-0.25205954909324646,-0.08363711833953857,-0.803784966468811,0.3485720753669739,-0.39176297187805176],[-0.8944721817970276,-0.09146858751773834,-0.048817411065101624,-0.03221786767244339,0.14971162378787994,0.23544767498970032,-0.5945754647254944,0.048346612602472305,0.025732897222042084,-0.08966928720474243,0.04102242738008499,0.09965965896844864],[-0.00497126579284668,-0.22112548351287842,-2.1787075996398926,0.36066383123397827,-0.22513234615325928,-0.10903863608837128,-0.24295371770858765,0.20368219912052155,-1.0950706005096436,-0.2724267244338989,0.010421235114336014,0.1451311558485031],[-0.2924911379814148,0.264126181602478,-0.017994003370404243,0.1904219388961792,0.04398790001869202,-0.05595690757036209,0.005974318832159042,-0.04355607181787491,-0.05246491730213165,-0.09018054604530334,0.22531819343566895,-0.05855701118707657],[0.15699885785579681,0.0057273805141448975,0.029716406017541885,0.06105861812829971,-0.04578716307878494,-0.0630362331867218,0.11294683814048767,0.16936665773391724,-0.05473984032869339,0.11588207632303238,-0.023634813725948334,-0.10929717123508453],[0.33663809299468994,1.9193885326385498,1.1729332208633423,1.2352879047393799,0.26866450905799866,0.2698501646518707,0.1985558569431305,-0.3415093719959259,0.06970397382974625,0.8207395076751709,0.28354546427726746,0.9034391641616821],[-0.17713510990142822,-0.03257058560848236,2.4880430698394775,0.0828595831990242,-1.209618330001831,0.38764286041259766,-1.1624231338500977,0.09608856588602066,0.15122757852077484,-0.13170620799064636,-0.01975012570619583,-0.06334562599658966],[0.0437442883849144,0.27756351232528687,0.0010266434401273727,0.47497791051864624,-0.11010842025279999,0.19258910417556763,0.11238044500350952,0.47061672806739807,0.09391490370035172,0.045786526054143906,0.09935048222541809,-0.25966876745224],[-0.05819308012723923,-0.06336840987205505,-0.10717733204364777,-0.039399147033691406,-0.18735401332378387,0.15486344695091248,0.0799737200140953,0.01947592943906784,0.041385650634765625,-0.05886710435152054,0.21845388412475586,-0.17910712957382202],[-0.1365678608417511,-0.24948696792125702,-0.20118993520736694,0.07397547364234924,0.12050814926624298,-0.18652862310409546,0.011613108217716217,2.8222508430480957,-0.0074574947357177734,0.07528018951416016,0.5913159847259521,0.2526225447654724],[-0.21369516849517822,0.07717274874448776,-0.3487119972705841,-0.07537136971950531,-0.29706454277038574,0.02698347717523575,-0.17574633657932281,-0.2279108762741089,-0.33434104919433594,-0.012749925255775452,-0.43710964918136597,-0.09722991287708282],[0.15608692169189453,-0.5279218554496765,0.07175523042678833,0.012573085725307465,-1.6704082489013672,-0.10854470729827881,-0.1292581856250763,-0.17145642638206482,0.19786059856414795,-0.22796568274497986,0.11236831545829773,0.0481741800904274]],\"type\":\"heatmap\",\"xaxis\":\"x\",\"yaxis\":\"y\",\"hovertemplate\":\"Head: %{x}<br>Layer: %{y}<br>color: %{z}<extra></extra>\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"scaleanchor\":\"y\",\"constrain\":\"domain\",\"title\":{\"text\":\"Head\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"autorange\":\"reversed\",\"constrain\":\"domain\",\"title\":{\"text\":\"Layer\"}},\"coloraxis\":{\"colorscale\":[[0.0,\"rgb(103,0,31)\"],[0.1,\"rgb(178,24,43)\"],[0.2,\"rgb(214,96,77)\"],[0.3,\"rgb(244,165,130)\"],[0.4,\"rgb(253,219,199)\"],[0.5,\"rgb(247,247,247)\"],[0.6,\"rgb(209,229,240)\"],[0.7,\"rgb(146,197,222)\"],[0.8,\"rgb(67,147,195)\"],[0.9,\"rgb(33,102,172)\"],[1.0,\"rgb(5,48,97)\"]],\"cmid\":0.0},\"title\":{\"text\":\"Logit Difference From Each Head\"}},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('f3d43306-a419-4086-8ea3-23187e75e554');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "per_head_residual, labels = cache.stack_head_results(\n",
    "    layer=-1, pos_slice=-1, return_labels=True\n",
    ")\n",
    "per_head_logit_diffs = residual_stack_to_logit_diff(per_head_residual, cache)\n",
    "per_head_logit_diffs = einops.rearrange(\n",
    "    per_head_logit_diffs,\n",
    "    \"(layer head_index) -> layer head_index\",\n",
    "    layer=model.cfg.n_layers,\n",
    "    head_index=model.cfg.n_heads,\n",
    ")\n",
    "imshow(\n",
    "    per_head_logit_diffs,\n",
    "    labels={\"x\": \"Head\", \"y\": \"Layer\"},\n",
    "    title=\"Logit Difference From Each Head\",\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- There's quite a lot going on here, with most heads contributing something.\n",
    "- The layer-2 drop in performance can mostly be attributed to L2H2.\n",
    "- The layer-2 recovery can be attributed to many heads, in order: L5H1, L5H3, L5H2, L5H11, L5H9. There are other heads which contribute to a lesser degree.\n",
    "- Even though the total gain from the layer-6 attention is small, it actually has one head which contributes a lot (L6H2), which is counterbalanced by two heads which detract (L6H4 and L6H6).\n",
    "- The performance gain in layer 9 is almost all down to L9H7.\n",
    "- The main culprit for latter performance loss is L11H4."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attention analysis\n",
    "\n",
    "Let's now zoom in on the important heads, and see what they're doing in terms of moving information about."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualise_attention_patterns(\n",
    "    head_indices: Union[List[int], int, Float[torch.Tensor, \"heads\"]],\n",
    "    batch_index: int = 0,\n",
    "    visualisation_type: str = \"attention_heads\",\n",
    ") -> RenderedHTML:\n",
    "    \"\"\"Visualise selected attention heads\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    head_indices: int or list or torch.Tensor\n",
    "        Indices of the heads to visualise, as integers in the range [0,\n",
    "        n_layers * n_heads)\n",
    "    batch_index: int, default=0\n",
    "        Which prompt to look at\n",
    "    visualisation_type: str, default=\"attention_heads\"\n",
    "        The type of visualisation to make. Either \"attention_heads\" or\n",
    "        \"attention_patterns\". The later can't label the heads.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    html: RenderedHTML\n",
    "        The HTML object built.\n",
    "    \"\"\"\n",
    "\n",
    "    if visualisation_type not in (\"attention_heads\", \"attention_patterns\"):\n",
    "        raise ValueError(\n",
    "            \"Parameter 'visualisation_type' must be one of 'attention_heads' \"\n",
    "            \"or 'attention_patterns'\"\n",
    "        )\n",
    "\n",
    "    if isinstance(head_indices, int):\n",
    "        head_indices = [head_indices]\n",
    "    elif isinstance(head_indices, list) or isinstance(head_indices, torch.Tensor):\n",
    "        head_indices = utils.to_numpy(head_indices)\n",
    "\n",
    "    labels = []\n",
    "    patterns = []\n",
    "    for head_index in head_indices:\n",
    "        layer = head_index // model.cfg.n_heads\n",
    "        head_index = head_index % model.cfg.n_heads\n",
    "        # Get the attention patterns for the head.\n",
    "        # Attention patterns have shape [batch, head_index, query_pos, key_pos]\n",
    "        patterns.append(cache[\"attn\", layer][batch_index, head_index])\n",
    "        labels.append(f\"L{layer}H{head_index}\")\n",
    "    str_tokens = model.to_str_tokens(prompt_tokens[batch_index])\n",
    "    patterns = torch.stack(patterns, dim=0)\n",
    "\n",
    "    # Plot the attention patterns\n",
    "    if visualisation_type == \"attention_heads\":\n",
    "        return cv.attention.attention_heads(\n",
    "            attention=patterns, tokens=str_tokens, attention_head_names=labels\n",
    "        )\n",
    "    elif visualisation_type == \"attention_patterns\":\n",
    "        return cv.attention.attention_patterns(attention=patterns, tokens=str_tokens)\n",
    "    else:\n",
    "        raise ValueError\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We look at the attention patterns of the top 3 positive and top 3 negative heads. The `circuitsvis` package has two different visualisers for attention patterns, each with their pros and cons. I use both below. We can look at different prompts by varying `batch_index`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_k = 3\n",
    "top_positive_logit_attr_heads = torch.topk(per_head_logit_diffs.flatten(), k=top_k).indices\n",
    "top_negative_logit_attr_heads = torch.topk(-per_head_logit_diffs.flatten(), k=top_k).indices\n",
    "top_logit_attr_heads = torch.cat((top_positive_logit_attr_heads, top_negative_logit_attr_heads))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The top 3 positive and top 3 negative heads. Prompt 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div id=\"circuits-vis-7c2365c8-40ec\" style=\"margin: 15px 0;\"/>\n",
       "    <script crossorigin type=\"module\">\n",
       "    import { render, AttentionHeads } from \"https://unpkg.com/circuitsvis@1.39.1/dist/cdn/esm.js\";\n",
       "    render(\n",
       "      \"circuits-vis-7c2365c8-40ec\",\n",
       "      AttentionHeads,\n",
       "      {\"attention\": [[[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.944133996963501, 0.05586601793766022, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8148710131645203, 0.08987775444984436, 0.0952511727809906, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8846431374549866, 0.011938918381929398, 0.09177216142416, 0.011645848862826824, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8580724596977234, 0.012214163318276405, 0.102970652282238, 0.004266275092959404, 0.022476406767964363, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.6068976521492004, 0.14837320148944855, 0.1541670858860016, 0.024985050782561302, 0.03738073259592056, 0.02819622866809368, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.5209348201751709, 0.1084015816450119, 0.041974663734436035, 0.11799698323011398, 0.07023140043020248, 0.10316614806652069, 0.0372944176197052, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.599215567111969, 0.08693921566009521, 0.10034775733947754, 0.026266779750585556, 0.04912257567048073, 0.03414681553840637, 0.08393353223800659, 0.02002779394388199, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.4967460334300995, 0.13384325802326202, 0.05138590931892395, 0.043701935559511185, 0.0206079613417387, 0.06523307412862778, 0.01986471563577652, 0.029148630797863007, 0.13946855068206787, 0.0, 0.0, 0.0, 0.0, 0.0], [0.4272976219654083, 0.07029208540916443, 0.07810816913843155, 0.011396357789635658, 0.0047195591032505035, 0.029710937291383743, 0.02637535147368908, 0.005997290834784508, 0.2884463965892792, 0.057656191289424896, 0.0, 0.0, 0.0, 0.0], [0.45726117491722107, 0.03589427098631859, 0.024888481944799423, 0.031330276280641556, 0.024491770192980766, 0.034887343645095825, 0.022819556295871735, 0.029096314683556557, 0.03667130321264267, 0.2919670343399048, 0.010692445561289787, 0.0, 0.0, 0.0], [0.21323658525943756, 0.0013471856946125627, 0.027948206290602684, 0.0024218212347477674, 0.005894813220947981, 0.0075418828055262566, 0.03844311833381653, 0.00276191090233624, 0.013403840363025665, 0.0019724073354154825, 0.6809164881706238, 0.004111775197088718, 0.0, 0.0], [0.0024885698221623898, 6.546704389620572e-05, 0.00043812402873300016, 0.00011703128984663635, 0.00028401269810274243, 0.00018565781647339463, 0.001607612008228898, 0.0001977327628992498, 0.0005875127972103655, 0.00018784771964419633, 0.9908949136734009, 0.0009221461950801313, 0.00202325452119112, 0.0], [0.021514609456062317, 0.00019538095511961728, 0.0014140465063974261, 6.3484170823358e-05, 4.7131197788985446e-05, 0.00018903266754932702, 0.0009336833609268069, 4.949416688759811e-05, 0.03359580785036087, 0.0017564158188179135, 0.934425950050354, 0.0004069340357091278, 0.0005557314143516123, 0.0048523214645683765]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9327447414398193, 0.06725522875785828, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.7099305987358093, 0.10632716864347458, 0.18374228477478027, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.7265281081199646, 0.0704159364104271, 0.1381874531507492, 0.06486853212118149, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.7045986652374268, 0.06363251060247421, 0.09338364750146866, 0.07466118782758713, 0.06372403353452682, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.7107897400856018, 0.03374287486076355, 0.08973761647939682, 0.08608495444059372, 0.04185454547405243, 0.03779019042849541, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.38761425018310547, 0.03895481303334236, 0.09149376302957535, 0.10337616503238678, 0.057767271995544434, 0.0776950791478157, 0.2430986762046814, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.36513394117355347, 0.046209558844566345, 0.07172149419784546, 0.08364022523164749, 0.07726240903139114, 0.06397354602813721, 0.1945008933544159, 0.09755796194076538, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.58941650390625, 0.039359334856271744, 0.03221680596470833, 0.03544031083583832, 0.015531203709542751, 0.022230539470911026, 0.051890742033720016, 0.05030996724963188, 0.16360466182231903, 0.0, 0.0, 0.0, 0.0, 0.0], [0.381931334733963, 0.03798624500632286, 0.04382016137242317, 0.043348319828510284, 0.029432373121380806, 0.06115949898958206, 0.0550248920917511, 0.07105337828397751, 0.16655312478542328, 0.10969064384698868, 0.0, 0.0, 0.0, 0.0], [0.34417757391929626, 0.026641864329576492, 0.016587555408477783, 0.03521408140659332, 0.030906520783901215, 0.05027998983860016, 0.054845452308654785, 0.06315425038337708, 0.08304652571678162, 0.11790645122528076, 0.17723974585533142, 0.0, 0.0, 0.0], [0.4910414218902588, 0.027619143947958946, 0.026839766651391983, 0.04263697564601898, 0.034952014684677124, 0.0329006090760231, 0.051986947655677795, 0.04985741898417473, 0.0974222794175148, 0.05909010395407677, 0.07786805927753448, 0.00778519781306386, 0.0, 0.0], [0.4588319659233093, 0.017052942886948586, 0.03473376855254173, 0.023502400144934654, 0.03267033398151398, 0.03902936354279518, 0.06424246728420258, 0.03698102757334709, 0.09905209392309189, 0.030355947092175484, 0.11357060819864273, 0.01548435352742672, 0.03449273109436035, 0.0], [0.5606710910797119, 0.02371544949710369, 0.014092191122472286, 0.01550117414444685, 0.015691228210926056, 0.013872387818992138, 0.04461071640253067, 0.03089292347431183, 0.09766818583011627, 0.05881284922361374, 0.05959846079349518, 0.02192191407084465, 0.015212520956993103, 0.027738917618989944]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8360552787780762, 0.16394475102424622, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.37104105949401855, 0.11983700841665268, 0.5091220140457153, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.38533681631088257, 0.16859744489192963, 0.37492120265960693, 0.07114458829164505, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.21163739264011383, 0.17162881791591644, 0.4029596149921417, 0.19899533689022064, 0.014778807759284973, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.2791511118412018, 0.04511186107993126, 0.5310498476028442, 0.10143763571977615, 0.016832910478115082, 0.026416629552841187, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.16523751616477966, 0.06289094686508179, 0.34518101811408997, 0.04633476212620735, 0.013220429420471191, 0.006304518785327673, 0.36083081364631653, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.2779477536678314, 0.06909236311912537, 0.25664055347442627, 0.031742941588163376, 0.012445975095033646, 0.011577841825783253, 0.28974390029907227, 0.05080868676304817, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.14069388806819916, 0.00854592677205801, 0.18485857546329498, 0.003402179339900613, 0.006441278848797083, 0.008042505010962486, 0.10160751640796661, 0.004472777713090181, 0.5419354438781738, 0.0, 0.0, 0.0, 0.0, 0.0], [0.07221679389476776, 0.006528369151055813, 0.02272423729300499, 0.008548935875296593, 0.0036060092970728874, 0.004820946604013443, 0.030148912221193314, 0.009784992784261703, 0.7552896738052368, 0.08633118122816086, 0.0, 0.0, 0.0, 0.0], [0.020968036726117134, 0.0015617741737514734, 0.0047913044691085815, 0.0013530628057196736, 0.001545271254144609, 0.0011320929042994976, 0.006537841632962227, 0.002396096708253026, 0.3166196346282959, 0.0373513288795948, 0.6057435274124146, 0.0, 0.0, 0.0], [0.002576112514361739, 0.00023238461290020496, 0.0007119569927453995, 0.0009203440276905894, 0.0009237875347025692, 0.0009324404527433217, 0.0017616971163079143, 0.0030066496692597866, 0.020426418632268906, 0.020900260657072067, 0.8187615275382996, 0.12884649634361267, 0.0, 0.0], [0.00019376559066586196, 4.3590334826149046e-05, 0.00018904068565461785, 8.161286677932367e-05, 3.0385428544832394e-05, 4.363650077721104e-05, 0.0006629162235185504, 0.00018544973863754421, 0.00592214846983552, 0.0029557181987911463, 0.6905803084373474, 0.09523987770080566, 0.20387151837348938, 0.0], [0.021915582939982414, 0.0009391565690748394, 0.004055518191307783, 0.000807305215857923, 0.0019098956836387515, 0.0012046975316479802, 0.008276468142867088, 0.0019009228562936187, 0.12516245245933533, 0.015425099059939384, 0.2995261251926422, 0.02490922622382641, 0.017159467563033104, 0.4768080413341522]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8898087739944458, 0.11019129306077957, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8202239871025085, 0.10055530816316605, 0.07922069728374481, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.7548615336418152, 0.09696808457374573, 0.07745648175477982, 0.07071387767791748, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.7098950743675232, 0.09185601025819778, 0.07486961036920547, 0.0688803493976593, 0.05449894815683365, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.6771231293678284, 0.08611343801021576, 0.06901195645332336, 0.0656755268573761, 0.05334185063838959, 0.04873407259583473, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.6439760327339172, 0.07924176007509232, 0.06330263614654541, 0.06034207344055176, 0.05023897439241409, 0.04481718689203262, 0.05808136984705925, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.5844615697860718, 0.07758666574954987, 0.06580325961112976, 0.06052261218428612, 0.04644293338060379, 0.043125659227371216, 0.05971179157495499, 0.06234551966190338, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.5353685021400452, 0.06867113709449768, 0.05851615592837334, 0.05704997107386589, 0.04476308822631836, 0.04158924147486687, 0.053596131503582, 0.06410209089517593, 0.07634363323450089, 0.0, 0.0, 0.0, 0.0, 0.0], [0.5125395059585571, 0.06266380846500397, 0.050165023654699326, 0.049185506999492645, 0.03896540775895119, 0.03410560265183449, 0.04688649624586105, 0.0546204075217247, 0.06853493303060532, 0.08233340829610825, 0.0, 0.0, 0.0, 0.0], [0.4725736081600189, 0.060777876526117325, 0.050246916711330414, 0.047271668910980225, 0.034858595579862595, 0.032485656440258026, 0.04567237198352814, 0.052005585283041, 0.06234804913401604, 0.07823590934276581, 0.06352374702692032, 0.0, 0.0, 0.0], [0.4379744529724121, 0.0544213205575943, 0.0470161959528923, 0.04107450693845749, 0.03373415023088455, 0.03337585926055908, 0.04339663311839104, 0.04646463692188263, 0.061612531542778015, 0.07299583405256271, 0.061896249651908875, 0.066037617623806, 0.0, 0.0], [0.42842966318130493, 0.053618621081113815, 0.044501177966594696, 0.04197771102190018, 0.031707748770713806, 0.030797097831964493, 0.04076419025659561, 0.044367920607328415, 0.05869234725832939, 0.06517066061496735, 0.05574607849121094, 0.06599515676498413, 0.038231633603572845, 0.0], [0.4037941098213196, 0.04876818507909775, 0.041879016906023026, 0.041080500930547714, 0.03172510489821434, 0.029105735942721367, 0.039272043853998184, 0.04525495693087578, 0.0561550036072731, 0.06782421469688416, 0.05498245358467102, 0.0624198354780674, 0.03757195919752121, 0.04016687348484993]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [7.091345651133452e-06, 0.9999929666519165, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [2.010435338206662e-07, 6.729220331180841e-05, 0.9999324083328247, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0005621518357656896, 0.024068623781204224, 0.0013264745939522982, 0.9740427136421204, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [3.462619702077063e-08, 1.1546745781743084e-07, 2.4399357698712265e-06, 9.188979106511397e-07, 0.999996542930603, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [2.7272213628748432e-05, 0.008050956763327122, 0.000238993379753083, 0.00023457543284166604, 0.00039299955824390054, 0.9910551309585571, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [4.37255076590759e-09, 4.6286035626508237e-07, 0.009907756000757217, 1.1871919980421808e-07, 2.853228124877205e-06, 1.4824906429566909e-05, 0.9900739192962646, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [1.5145320730880485e-07, 4.706113031716086e-05, 4.804051627615991e-07, 5.452071491163224e-06, 7.152591570047662e-05, 0.002153471577912569, 7.50980098018772e-06, 0.9977142810821533, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [5.431595617721996e-09, 2.3856324915527694e-08, 1.3072329885233103e-09, 9.657560084974648e-09, 2.022267153733992e-08, 3.965316608400826e-08, 5.079072273872498e-09, 2.3260629689048073e-07, 0.9999996423721313, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0001176758305518888, 0.000671248824801296, 0.00021231058053672314, 3.239244324504398e-05, 7.447772077284753e-05, 0.0023801967035979033, 0.0010658749379217625, 0.009922487661242485, 9.836094250204042e-07, 0.9855222702026367, 0.0, 0.0, 0.0, 0.0], [2.844269307925029e-12, 1.2450994402168902e-10, 4.251443897373974e-05, 4.207941495248946e-10, 6.624748749572973e-09, 1.2748365030290643e-08, 0.004114440176635981, 2.8473689184238538e-08, 5.513217920388724e-12, 5.193278411752544e-07, 0.9958423972129822, 0.0, 0.0, 0.0], [3.7603955505005615e-09, 2.6022600650321692e-05, 1.606984483260021e-06, 4.029110277770087e-05, 1.869221506467511e-07, 6.4992877923941705e-06, 2.2256408556131646e-06, 1.8475133401807398e-05, 1.1293201396256336e-07, 1.0707178262236994e-05, 1.4477881222774158e-06, 0.9998923540115356, 0.0, 0.0], [1.317733300254531e-08, 2.343824780837167e-05, 2.743109689617995e-06, 8.61472315705214e-08, 1.676593370802948e-07, 8.27219701022841e-05, 5.558946941164322e-05, 3.1380506698042154e-05, 2.323739181520068e-06, 0.00018860526324715465, 0.00027932357625104487, 9.997415327234194e-05, 0.999233603477478, 0.0], [0.0002877731458283961, 0.0003714509366545826, 3.6991875731473556e-06, 1.5755100321257487e-05, 6.366689194692299e-05, 0.0001119544540415518, 3.0637409054179443e-06, 0.0002231262915302068, 0.00140286423265934, 0.002279530744999647, 1.3072988735984836e-07, 4.046213689434808e-06, 2.2726733732270077e-05, 0.9952101111412048]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.00016169666196219623, 0.9998382329940796, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [2.6014035029220395e-05, 0.0006824135198257864, 0.9992915391921997, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0006661221850663424, 0.0019208953017368913, 0.0007025212980806828, 0.9967104196548462, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [3.037881924683461e-06, 5.955268534307834e-06, 1.0043929705716437e-06, 1.8214241208625026e-05, 0.999971866607666, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [1.0077878869196866e-05, 4.275515948393149e-06, 1.1309354022159823e-06, 0.00045009428868070245, 0.0005435802158899605, 0.9989908337593079, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [1.5108691513887607e-05, 1.2399449360600556e-06, 2.5212353648385033e-05, 0.0025070998817682266, 0.0019200871465727687, 0.022373516112565994, 0.9731578230857849, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [8.26731320557883e-06, 4.102628736291081e-06, 1.6885387310594524e-07, 0.0017192128580063581, 0.0004374654090497643, 0.0026618128176778555, 0.0008164621540345252, 0.9943524599075317, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [1.8715509213507175e-05, 2.354476009713835e-06, 2.579435431471211e-06, 1.49112893268466e-05, 9.360047988593578e-05, 8.78691571415402e-05, 9.008752385852858e-05, 0.0011775519233196974, 0.998512327671051, 0.0, 0.0, 0.0, 0.0, 0.0], [3.4560744097689167e-06, 2.4647788450238295e-05, 2.3046393948789046e-07, 8.08628919912735e-06, 3.793059249801445e-06, 5.276368756312877e-05, 5.1641272875713184e-06, 3.0077881092438474e-06, 0.00016935403982643038, 0.9997294545173645, 0.0, 0.0, 0.0, 0.0], [0.00014256952272262424, 1.0366070455347653e-06, 1.4309358675745898e-07, 1.157742872237577e-06, 1.3674922172413062e-07, 2.5404976895515574e-06, 3.106557358023565e-07, 2.129629166347513e-07, 7.088843176461523e-06, 0.005527174565941095, 0.9943175911903381, 0.0, 0.0, 0.0], [0.00022620857635047287, 3.3930443805729738e-06, 1.4903959177914317e-09, 1.1450956804992529e-07, 3.2446927367146827e-09, 8.857934385986255e-10, 1.9208325208186494e-10, 1.3221748140779255e-08, 3.890708555331912e-08, 1.026387064229084e-08, 6.044260771886911e-07, 0.9997696280479431, 0.0, 0.0], [8.944807632360607e-06, 4.152577730565099e-07, 8.774534987487925e-10, 2.747266858449393e-10, 6.505543066054331e-12, 8.437059210997244e-12, 1.1643835852101492e-12, 3.8236527659385455e-12, 2.1589059706617064e-10, 1.2797644888262738e-12, 1.6501546656888522e-11, 0.0007580125238746405, 0.9992326498031616, 0.0], [2.6182347028225195e-06, 4.271970510671963e-07, 3.063619757881497e-08, 7.955288094940727e-10, 1.3753771342314702e-12, 3.2115778786367954e-11, 3.127485423415344e-11, 8.095119193030076e-12, 8.248238897445859e-11, 5.798226829223374e-11, 2.351786321241889e-09, 1.5191488273558207e-05, 0.00021739385556429625, 0.9997643828392029]]], \"attentionHeadNames\": [\"L9H7\", \"L6H2\", \"L5H1\", \"L2H2\", \"L11H4\", \"L6H4\"], \"tokens\": [\"<|endoftext|>\", \"model\", \".\", \"dat\", \"as\", \"et\", \".\", \"data\", \" =\", \" table\", \"['\", \"respond\", \"er\", \"'\"]}\n",
       "    )\n",
       "    </script>"
      ],
      "text/plain": [
       "<circuitsvis.utils.render.RenderedHTML at 0x7fd982b2e550>"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_index = 1\n",
    "print(f\"The top {top_k} positive and top {top_k} negative heads. Prompt {batch_index}\")\n",
    "visualise_attention_patterns(top_logit_attr_heads, batch_index=batch_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The same heads with a different visualiser\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div id=\"circuits-vis-47704778-0cf7\" style=\"margin: 15px 0;\"/>\n",
       "    <script crossorigin type=\"module\">\n",
       "    import { render, AttentionPatterns } from \"https://unpkg.com/circuitsvis@1.39.1/dist/cdn/esm.js\";\n",
       "    render(\n",
       "      \"circuits-vis-47704778-0cf7\",\n",
       "      AttentionPatterns,\n",
       "      {\"tokens\": [\"<|endoftext|>\", \"<\", \"html\", \" style\", \"='\", \"b\", \".\", \"blue\", \" {\", \"color\", \":\", \" blue\", \"}\", \"'\"], \"attention\": [[[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.96597820520401, 0.034021731466054916, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.17941682040691376, 0.6387022733688354, 0.1818808913230896, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.16377292573451996, 0.5285374522209167, 0.2798270285129547, 0.0278625525534153, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8075311779975891, 0.0014820036012679338, 0.0765538290143013, 0.0910920798778534, 0.023340895771980286, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.5446021556854248, 0.003161256667226553, 0.007456421852111816, 0.017098981887102127, 0.42216241359710693, 0.005518686957657337, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.3618978261947632, 0.0072532715275883675, 0.04152648523449898, 0.07369458675384521, 0.19232772290706635, 0.0720364898443222, 0.2512635588645935, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.023472260683774948, 0.017914988100528717, 0.0014441428938880563, 0.0015196707099676132, 0.918471097946167, 0.002716976683586836, 0.03202665224671364, 0.0024342096876353025, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.2627565562725067, 0.0012849034974351525, 0.008427017368376255, 0.019423726946115494, 0.20540598034858704, 0.009850523434579372, 0.05673946440219879, 0.029003262519836426, 0.40710851550102234, 0.0, 0.0, 0.0, 0.0, 0.0], [0.06292399019002914, 0.0004606475995387882, 0.00037363337469287217, 0.0005686415825039148, 0.01889718882739544, 0.0011022741673514247, 0.04215690493583679, 0.00562073802575469, 0.7831087708473206, 0.08478724956512451, 0.0, 0.0, 0.0, 0.0], [0.5064440369606018, 0.0008145430474542081, 0.004039246588945389, 0.0018734248587861657, 0.006384513806551695, 0.00969584658741951, 0.07552657276391983, 0.2455768883228302, 0.04192672669887543, 0.06329988688230515, 0.044418372213840485, 0.0, 0.0, 0.0], [2.6694262487581e-05, 0.00011077894305344671, 2.396445779595524e-07, 2.031697931670351e-06, 0.0051513309590518475, 7.989489859028254e-06, 5.3274925448931754e-05, 1.026653808366973e-05, 0.989935576915741, 0.00036195627762936056, 0.004268697928637266, 7.116718916222453e-05, 0.0, 0.0], [0.018648630008101463, 0.01603756658732891, 0.00035406870301812887, 0.0009343711426481605, 0.7199341654777527, 0.004403400234878063, 0.013494787737727165, 0.0011078253155574203, 0.17862802743911743, 0.00032188923796638846, 0.005371174309402704, 0.00018539626034907997, 0.04057866334915161, 0.0], [0.07121698558330536, 0.5280370712280273, 0.1122070699930191, 0.051595836877822876, 0.16404536366462708, 0.002660411410033703, 0.01044817641377449, 0.0020800933707505465, 0.03519751876592636, 0.00021942787861917168, 0.0004300464643165469, 0.00017578370170667768, 0.003545424435287714, 0.018140848726034164]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.7185965180397034, 0.28140348196029663, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.710983395576477, 0.08378849923610687, 0.20522809028625488, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.6034260392189026, 0.079208604991436, 0.18688863515853882, 0.13047663867473602, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.6034256815910339, 0.05595726519823074, 0.05499565973877907, 0.13601019978523254, 0.149611234664917, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.7087523341178894, 0.023495588451623917, 0.03372560068964958, 0.07490447908639908, 0.06710783392190933, 0.09201422333717346, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.5748857855796814, 0.01664278842508793, 0.059471458196640015, 0.07421006262302399, 0.070086270570755, 0.09383660554885864, 0.11086704581975937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.5941569805145264, 0.01687515340745449, 0.038589246571063995, 0.041668850928545, 0.05473565310239792, 0.04867709428071976, 0.09978808462619781, 0.10550885647535324, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.4022625982761383, 0.01109866239130497, 0.03191938251256943, 0.044361088424921036, 0.02866828627884388, 0.0789366140961647, 0.05257730558514595, 0.1425129771232605, 0.20766308903694153, 0.0, 0.0, 0.0, 0.0, 0.0], [0.4583204984664917, 0.012887228280305862, 0.007685194723308086, 0.010616365820169449, 0.07030832022428513, 0.06268277764320374, 0.0525965616106987, 0.06836947798728943, 0.08210974931716919, 0.17442382872104645, 0.0, 0.0, 0.0, 0.0], [0.371324360370636, 0.006341760046780109, 0.0018108348594978452, 0.004992880392819643, 0.04582137614488602, 0.04992254823446274, 0.03708626702427864, 0.04742999002337456, 0.05656706541776657, 0.14420902729034424, 0.2344939410686493, 0.0, 0.0, 0.0], [0.40137001872062683, 0.004167864099144936, 0.0017134299268946052, 0.009821368381381035, 0.014088007621467113, 0.041372619569301605, 0.040217213332653046, 0.058174170553684235, 0.056639909744262695, 0.16303342580795288, 0.08466213196516037, 0.12473984062671661, 0.0, 0.0], [0.3875235617160797, 0.002504577860236168, 0.0020951011683791876, 0.007367895450443029, 0.021034948527812958, 0.0223982073366642, 0.02407284453511238, 0.02593212202191353, 0.08129724115133286, 0.047465503215789795, 0.0716690644621849, 0.0434960275888443, 0.2631429433822632, 0.0], [0.34618309140205383, 0.018304772675037384, 0.011908642947673798, 0.030798425897955894, 0.07341563701629639, 0.01580195687711239, 0.02877998910844326, 0.007439130917191505, 0.0472412146627903, 0.024830728769302368, 0.05048290640115738, 0.009262475185096264, 0.19174247980117798, 0.14380857348442078]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.6424080729484558, 0.3575919568538666, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.2679154574871063, 0.4514668583869934, 0.28061771392822266, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.041884809732437134, 0.2039213925600052, 0.5326935648918152, 0.22150029242038727, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0027203066274523735, 0.015818342566490173, 0.09644991904497147, 0.06129923090338707, 0.8237122297286987, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.025320885702967644, 0.0288238562643528, 0.1326899230480194, 0.0990295335650444, 0.5856692790985107, 0.12846651673316956, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.006425859872251749, 0.03175371140241623, 0.027115045115351677, 0.02931455336511135, 0.7701742649078369, 0.08668246120214462, 0.04853411018848419, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.01117338240146637, 0.016177356243133545, 0.00815280620008707, 0.024145303294062614, 0.26646387577056885, 0.19245807826519012, 0.24902530014514923, 0.2324039489030838, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.006382356863468885, 0.024565955623984337, 0.008599644526839256, 0.03620219603180885, 0.40444111824035645, 0.047806501388549805, 0.04085388407111168, 0.024999165907502174, 0.40614914894104004, 0.0, 0.0, 0.0, 0.0, 0.0], [1.1868655747093726e-05, 3.2423668017145246e-05, 0.0001934106257976964, 0.0005628701183013618, 0.007214548997581005, 0.00023195553512778133, 0.00024274214229080826, 0.0012784118298441172, 0.7780994772911072, 0.21213236451148987, 0.0, 0.0, 0.0, 0.0], [6.83177204336971e-05, 0.00030887959292158484, 0.0006589399999938905, 0.0009543823543936014, 0.010872796177864075, 0.0004884801455773413, 0.0035242459271103144, 0.0009028537315316498, 0.812335193157196, 0.12059393525123596, 0.04929207265377045, 0.0, 0.0, 0.0], [2.9681054002139717e-05, 0.00014558150724042207, 9.98321866063634e-06, 0.00013830623356625438, 0.005135060753673315, 0.0002621020539663732, 0.0005703495698980987, 0.00036037902464158833, 0.2288888543844223, 0.03317929059267044, 0.7261627912521362, 0.005117583088576794, 0.0, 0.0], [0.008168375119566917, 0.019573181867599487, 0.0004671564674936235, 0.006466814316809177, 0.36015787720680237, 0.010097289457917213, 0.02538195624947548, 0.0023040948435664177, 0.12263491749763489, 0.0065276180393993855, 0.11298137158155441, 0.0016365027986466885, 0.3236028850078583, 0.0], [0.06951707601547241, 0.19710850715637207, 0.026137860491871834, 0.07020677626132965, 0.029524164274334908, 0.013540449552237988, 0.0044754622504115105, 0.000689534586854279, 0.02208661288022995, 0.0008612051024101675, 0.016949808225035667, 0.00015574523422401398, 0.09614211320877075, 0.45260459184646606]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8944551348686218, 0.10554485023021698, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8114891052246094, 0.09898550063371658, 0.08952537924051285, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.7438944578170776, 0.08813657611608505, 0.08588739484548569, 0.08208146691322327, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.6783889532089233, 0.08013437688350677, 0.07420042157173157, 0.08165886998176575, 0.08561734855175018, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.6494960784912109, 0.0770675465464592, 0.07208754122257233, 0.07845127582550049, 0.08332598954439163, 0.0395716056227684, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.6268622875213623, 0.06948067992925644, 0.0668611153960228, 0.07128474116325378, 0.0740310400724411, 0.03713415190577507, 0.054345957934856415, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.5847475528717041, 0.06316884607076645, 0.0633927434682846, 0.06548088788986206, 0.07231420278549194, 0.03440070524811745, 0.054773248732089996, 0.06172187626361847, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.541599452495575, 0.0595070905983448, 0.059759583324193954, 0.06620457768440247, 0.06455951184034348, 0.03256109356880188, 0.04742138460278511, 0.05737621337175369, 0.07101116329431534, 0.0, 0.0, 0.0, 0.0, 0.0], [0.5058781504631042, 0.056417305022478104, 0.05634487792849541, 0.05865105614066124, 0.06482534110546112, 0.031917933374643326, 0.04722031578421593, 0.05699966475367546, 0.06528222560882568, 0.056463126093149185, 0.0, 0.0, 0.0, 0.0], [0.48111701011657715, 0.05554439499974251, 0.05433797091245651, 0.05949350446462631, 0.059557199478149414, 0.030681489035487175, 0.04429692402482033, 0.05372052639722824, 0.061070043593645096, 0.05423325300216675, 0.04594779387116432, 0.0, 0.0, 0.0], [0.4663153886795044, 0.04888435825705528, 0.0485244020819664, 0.05229691416025162, 0.05397042632102966, 0.02771471068263054, 0.04148132726550102, 0.048711322247982025, 0.055477309972047806, 0.050910405814647675, 0.04382137209177017, 0.06189209222793579, 0.0, 0.0], [0.44541865587234497, 0.04829634726047516, 0.0465412437915802, 0.04892976954579353, 0.047904111444950104, 0.025793958455324173, 0.03703179955482483, 0.04607676342129707, 0.053423404693603516, 0.04970169812440872, 0.03859531506896019, 0.060543809086084366, 0.051743097603321075, 0.0], [0.41868484020233154, 0.04306232929229736, 0.045548345893621445, 0.047886475920677185, 0.04884424805641174, 0.02680071070790291, 0.036869026720523834, 0.04547872021794319, 0.050051841884851456, 0.04674340784549713, 0.038080718368291855, 0.05811581760644913, 0.05020252242684364, 0.043630994856357574]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0005011075991205871, 0.9994988441467285, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [4.3571657393215446e-10, 2.440444404783193e-05, 0.9999755620956421, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [7.602022833452793e-08, 0.00021134995040483773, 0.0010877003660425544, 0.9987008571624756, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [1.0632109479047358e-05, 0.0006255820044316351, 2.392609076196095e-06, 0.0017726995283737779, 0.9975887537002563, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [3.1826111808186397e-06, 2.2095662643550895e-05, 4.9974855755863246e-06, 0.0038692099042236805, 0.0022464217618107796, 0.9938541650772095, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [4.920702849631198e-07, 0.00019763977616094053, 3.762745492963404e-08, 0.00046677119098603725, 0.005219312384724617, 0.00013092525477986783, 0.9939848780632019, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [2.3165037532635324e-07, 4.9055634008254856e-05, 3.6382239159138408e-06, 1.3350781955523416e-05, 1.4473518604063429e-05, 1.2263451765193167e-07, 1.3975923138787039e-05, 0.9999051094055176, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [3.163689754615007e-08, 9.345706644126039e-07, 1.2891656631097703e-09, 6.372227971951361e-07, 2.7687496185535565e-05, 3.499860179445591e-09, 2.25365283768042e-06, 9.621565550332889e-05, 0.9998723268508911, 0.0, 0.0, 0.0, 0.0, 0.0], [3.2083811163374776e-09, 1.106582345755669e-07, 7.692694481420403e-08, 6.556240350619191e-06, 2.830844039181102e-07, 4.252457941333887e-09, 2.1572255093360582e-08, 8.98525684078777e-07, 7.660197297809646e-06, 0.9999843835830688, 0.0, 0.0, 0.0, 0.0], [3.229637737800495e-11, 4.059644634346604e-11, 4.87620740226985e-13, 1.453088344094411e-10, 1.0013213369575169e-08, 7.546211919229329e-13, 8.245148563901239e-09, 3.5944859178016486e-07, 0.00010523804667172953, 9.185348608298227e-05, 0.9998025298118591, 0.0, 0.0, 0.0], [3.8857990602991777e-08, 5.493483286045375e-07, 7.832842925381556e-07, 4.497176632867195e-06, 3.960473407005338e-07, 1.8442719573741329e-10, 1.0893738817685517e-06, 0.0014526357408612967, 0.0001321735035162419, 0.0004370172100607306, 0.0001594575442140922, 0.9978113770484924, 0.0, 0.0], [4.222746611048933e-06, 9.063556717592292e-06, 5.093767322250642e-05, 0.000170250961673446, 8.48156832944369e-06, 3.4139297611091024e-08, 8.807982680991699e-07, 5.973171028017532e-06, 1.5812121318958816e-06, 0.0002812757156789303, 9.095806490222458e-07, 0.0001061158545780927, 0.9993602633476257, 0.0], [8.566377118768287e-08, 7.37371510695084e-06, 0.0017726435326039791, 0.0027732152957469225, 1.9595975686570455e-07, 7.972289495228324e-09, 3.004520010563283e-07, 8.208118060792913e-07, 1.2542179206320725e-07, 8.623294888820965e-06, 1.9673169759926168e-08, 2.1449629912240198e-06, 0.0006783733842894435, 0.9947561025619507]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.005255510099232197, 0.9947445392608643, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.00034312449861317873, 2.895970465033315e-05, 0.999627947807312, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [2.410154411336407e-05, 9.60166744334856e-07, 0.00029602929134853184, 0.9996789693832397, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [1.0971998563036323e-05, 4.230043657571514e-07, 5.151130608282983e-06, 0.0003877496055793017, 0.9995957016944885, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.00013005825167056173, 4.0503882701159455e-06, 4.9028752982849255e-05, 2.0419179236341733e-06, 5.064943979959935e-05, 0.9997641444206238, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [8.911190889193676e-06, 1.1611161454538887e-07, 1.258610211607447e-07, 3.2237972291682127e-09, 1.8357644293587327e-09, 0.0002999219868797809, 0.9996908903121948, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [8.72435120982118e-05, 3.788084768530098e-06, 9.319278433395084e-06, 5.3967846724845e-06, 9.456173444277738e-08, 2.2735011953045614e-05, 7.918871415313333e-05, 0.9997922778129578, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.00040436661220155656, 7.35743305995129e-05, 1.848067040555179e-05, 1.4117987120698672e-05, 2.7464218419481767e-06, 3.3052654089260614e-06, 1.0427085044284468e-06, 0.0002016514481510967, 0.9992806315422058, 0.0, 0.0, 0.0, 0.0, 0.0], [6.89566968503641e-06, 1.4652857771579875e-06, 3.826812644547317e-06, 6.411755293811439e-06, 4.150973609284847e-07, 7.859810466470663e-06, 1.2459056009106462e-08, 1.097513177228393e-06, 0.0007395618013106287, 0.9992325305938721, 0.0, 0.0, 0.0, 0.0], [5.837425123900175e-05, 2.4757732717262115e-06, 0.00015354478091467172, 2.776678593363613e-05, 6.257562290556962e-07, 3.3395505738553766e-07, 5.101633604454037e-08, 1.428026052963105e-06, 0.00026192530640400946, 0.00104054668918252, 0.9984530210494995, 0.0, 0.0, 0.0], [1.2766001418640371e-05, 2.539769354825694e-07, 1.3042816135566682e-05, 6.341962034639437e-06, 6.256021034545256e-09, 2.0079612568224547e-06, 4.9338493290917995e-09, 0.0002587140479590744, 4.456393071450293e-05, 8.528311445843428e-05, 0.0001325753255514428, 0.9994445443153381, 0.0, 0.0], [3.3891152270371094e-05, 1.2139497812313493e-05, 5.440589120553341e-06, 1.9198042267021265e-08, 2.9889712926944867e-10, 6.738336999490002e-09, 4.180777750661946e-07, 2.785124479487422e-06, 2.912691888923291e-05, 3.516115327784064e-07, 2.5474919311818667e-05, 6.69858400215162e-06, 0.9998835325241089, 0.0], [0.0018335608765482903, 1.655317100812681e-05, 0.00017253572877962142, 6.953368028916884e-06, 5.999871177664318e-07, 4.461331172933569e-06, 2.555098319589888e-07, 1.3793854805044248e-06, 3.0485338356811553e-05, 1.338447145826649e-05, 5.9045880334451795e-05, 1.1320883459120523e-05, 0.003239146200940013, 0.9946103096008301]]]}\n",
       "    )\n",
       "    </script>"
      ],
      "text/plain": [
       "<circuitsvis.utils.render.RenderedHTML at 0x7fd98293a110>"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"The same heads with a different visualiser\")\n",
    "visualise_attention_patterns(top_logit_attr_heads, visualisation_type=\"attention_patterns\", batch_index=batch_index)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The attention pattern of L5H1 is the clearest to analyse.\n",
    "    * It works on all 'scoping symbols': opening and closing bracket *and quotation marks*.\n",
    "    * It sends from every scoping symbol, and the BOS token, to all the subsequent tokens until the next scoping symbol.\n",
    "    * It seems to ignore the '()' tokens, rather than counting them as new scoping symbols.\n",
    "- It's a bit less clear what L6H2 is doing.\n",
    "    * It sends from certain key symbols: the BOS token, `.`, `,`, `=`, `(`, `[` and `'`.\n",
    "    * It mostly sends to all subsequent tokens, though sometimes it pays attention to scope.\n",
    "- The attention patterns for L9H7 are more complex.\n",
    "    * What's clear is that it sends information from the BOS token, opening brackets *and quotation marks* to some tokens within their scope.\n",
    "    * Actually the condition of being inside the scope gets violated in one instance: in prompt 3 information is sent from the first quotation mark to tokens inside the scope of the third. I'm not sure if this is 'intentional' or 'accidental'. Testing more examples would help.\n",
    "    * It seems plausible that L9H7 is using the computation from L5H1 to compute these activation patterns.\n",
    "    * One striking feature is the way the attention pattern seems to alternate between opening brackets.\n",
    "    * The patterns are similar to what we'd get if we set tokens to receive information depending on the parity of the current bracket depth, though not quite.\n",
    "    * Knowing the parity alone is not enough to solve the task, but the model is probably transferring important data according to this activation pattern which allows it to solve the task.\n",
    "- The activation patterns of the negative heads are not very interesting.\n",
    "    * I suppose their negative effects come from *what* gets transferred according to the patterns."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mech-interp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
